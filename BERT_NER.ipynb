{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b3b2c0b-a612-4843-9938-d6257d1551e4",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e862ba-0f63-4b9b-864e-7a59dbdf7dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForTokenClassification,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca55bab6-edcf-4182-9175-0b60f6c8cfd3",
   "metadata": {},
   "source": [
    "## 2. DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81bdc49b-5d25-4ca9-a49e-80aae9b6e89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes - Train: 51, Dev: 23, Test: 248\n"
     ]
    }
   ],
   "source": [
    "# Deine lokalen Windows-Pfade\n",
    "TRAIN_DIR = Path(r\"C:\\Users\\nmilo\\OneDrive\\Desktop\\Master\\Semester2\\NLP\\project\\dataset\\train\")\n",
    "DEV_DIR   = Path(r\"C:\\Users\\nmilo\\OneDrive\\Desktop\\Master\\Semester2\\NLP\\project\\dataset\\dev\")\n",
    "TEST_DIR  = Path(r\"C:\\Users\\nmilo\\OneDrive\\Desktop\\Master\\Semester2\\NLP\\project\\dataset\\test\")\n",
    "\n",
    "assert TRAIN_DIR.exists(), f\"Train-Ordner nicht gefunden: {TRAIN_DIR}\"\n",
    "assert DEV_DIR.exists(),   f\"Dev-Ordner nicht gefunden:   {DEV_DIR}\"\n",
    "assert TEST_DIR.exists(),  f\"Test-Ordner nicht gefunden:  {TEST_DIR}\"\n",
    "def load_docie_docs(folder: Path, recursive: bool = False):\n",
    "    \"\"\"Load DocIE documents from JSON files.\"\"\"\n",
    "    docs = []\n",
    "    pattern = \"**/*.json\" if recursive else \"*.json\"\n",
    "    for file in folder.glob(pattern):\n",
    "        data = json.loads(file.read_text(encoding=\"utf-8\"))\n",
    "        if isinstance(data, list):\n",
    "            docs.extend(data)\n",
    "        else:\n",
    "            docs.append(data)\n",
    "    return docs\n",
    "\n",
    "# Load data\n",
    "train_docs = load_docie_docs(TRAIN_DIR)\n",
    "dev_docs = load_docie_docs(DEV_DIR)\n",
    "test_docs = load_docie_docs(TEST_DIR, recursive=True)\n",
    "\n",
    "print(f\"Dataset sizes - Train: {len(train_docs)}, Dev: {len(dev_docs)}, Test: {len(test_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb7ba20-3745-4c32-931d-5ae68654edfd",
   "metadata": {},
   "source": [
    "## 3. LABEL MAPPING SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96443f17-e814-4ad1-8a2d-6127988ce06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NER labels: 39\n",
      "Entity types: ['CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MISC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART']\n"
     ]
    }
   ],
   "source": [
    "# Extract entity types from training data\n",
    "entity_types = set()\n",
    "for doc in train_docs:\n",
    "    if \"entity_label_set\" in doc:\n",
    "        entity_types.update(doc[\"entity_label_set\"])\n",
    "    elif \"NER_label_set\" in doc:\n",
    "        entity_types.update(doc[\"NER_label_set\"])\n",
    "\n",
    "entity_types = sorted(list(entity_types))\n",
    "\n",
    "# Create BIO labels\n",
    "ner_labels = [\"O\"]\n",
    "for entity_type in entity_types:\n",
    "    ner_labels.extend([f\"B-{entity_type}\", f\"I-{entity_type}\"])\n",
    "\n",
    "# Create label mappings\n",
    "label2id = {label: idx for idx, label in enumerate(ner_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(f\"Number of NER labels: {len(ner_labels)}\")\n",
    "print(f\"Entity types: {entity_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83eb915-fccb-4d89-abe6-4df65db5927e",
   "metadata": {},
   "source": [
    "## 4. TOKENIZATION AND DATASET PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db1a830d-7aae-447c-952b-7e13764048ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44e089fcb6f4f10adde6fa20dd4dfbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c77ef11aad45659543a9bb5681d860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized dataset sizes - Train: 166, Dev: 74\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# Tokenization parameters\n",
    "max_length = 512\n",
    "stride = 128\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    \"\"\"Tokenize text and align NER labels with subword tokens.\"\"\"\n",
    "    all_input_ids = []\n",
    "    all_attention_mask = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for doc, entities in zip(examples[\"doc\"], examples[\"entities\"]):\n",
    "        # Tokenize with return_offsets_mapping for alignment\n",
    "        tokenized = tokenizer(\n",
    "            doc,\n",
    "            return_offsets_mapping=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            stride=stride,\n",
    "            return_overflowing_tokens=True,\n",
    "        )\n",
    "        \n",
    "        # Process each chunk\n",
    "        for i in range(len(tokenized[\"input_ids\"])):\n",
    "            input_ids = tokenized[\"input_ids\"][i]\n",
    "            attention_mask = tokenized[\"attention_mask\"][i]\n",
    "            offsets = tokenized[\"offset_mapping\"][i]\n",
    "            \n",
    "            # Initialize labels as \"O\"\n",
    "            chunk_labels = [\"O\"] * len(input_ids)\n",
    "            \n",
    "            # Align entity labels\n",
    "            for entity in entities:\n",
    "                entity_type = entity[\"type\"]\n",
    "                for mention in entity.get(\"mentions\", []):\n",
    "                    start_char = doc.find(mention)\n",
    "                    if start_char == -1:\n",
    "                        continue\n",
    "                    end_char = start_char + len(mention)\n",
    "                    \n",
    "                    # Find tokens that overlap with entity\n",
    "                    for idx, (token_start, token_end) in enumerate(offsets):\n",
    "                        if token_start >= start_char and token_end <= end_char:\n",
    "                            if token_start == start_char:\n",
    "                                chunk_labels[idx] = f\"B-{entity_type}\"\n",
    "                            else:\n",
    "                                chunk_labels[idx] = f\"I-{entity_type}\"\n",
    "            \n",
    "            # Convert labels to IDs\n",
    "            label_ids = [label2id.get(label, label2id[\"O\"]) for label in chunk_labels]\n",
    "            \n",
    "            # Special tokens get -100 (ignored in loss)\n",
    "            label_ids = [\n",
    "                -100 if offsets[i] == (0, 0) else label_ids[i] \n",
    "                for i in range(len(label_ids))\n",
    "            ]\n",
    "            \n",
    "            all_input_ids.append(input_ids)\n",
    "            all_attention_mask.append(attention_mask)\n",
    "            all_labels.append(label_ids)\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": all_input_ids,\n",
    "        \"attention_mask\": all_attention_mask,\n",
    "        \"labels\": all_labels,\n",
    "    }\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "hf_train = Dataset.from_list(train_docs)\n",
    "hf_dev = Dataset.from_list(dev_docs)\n",
    "hf_test = Dataset.from_list(test_docs)\n",
    "\n",
    "# Apply tokenization\n",
    "columns_to_remove = [\"domain\", \"title\", \"doc\", \"entities\", \"triples\", \n",
    "                     \"label_set\", \"entity_label_set\", \"document\", \n",
    "                     \"RE_label_set\", \"NER_label_set\", \"id\"]\n",
    "\n",
    "tokenized_train = hf_train.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=[col for col in columns_to_remove if col in hf_train.column_names]\n",
    ")\n",
    "\n",
    "tokenized_dev = hf_dev.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=[col for col in columns_to_remove if col in hf_dev.column_names]\n",
    ")\n",
    "\n",
    "print(f\"Tokenized dataset sizes - Train: {len(tokenized_train)}, Dev: {len(tokenized_dev)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad21fc8-a4a1-4566-9257-46ed82a1f0aa",
   "metadata": {},
   "source": [
    "## 5. METRICS AND DATA COLLATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f4fe3bf-6a30-4a04-bfa2-6ac969369207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator for padding\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute precision, recall, and F1 for NER.\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    # Flatten and remove special tokens (-100)\n",
    "    predictions = predictions.flatten()\n",
    "    labels = labels.flatten()\n",
    "    mask = labels != -100\n",
    "    \n",
    "    predictions = predictions[mask]\n",
    "    labels = labels[mask]\n",
    "    \n",
    "    # Compute metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='micro', zero_division=0\n",
    "    )\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"accuracy\": accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752ede33-d531-4515-b3ba-21aa11f1345c",
   "metadata": {},
   "source": [
    "## 6. BASELINE MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41fc40e6-23df-4872-ac9e-48386eab3048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRAINING BASELINE MODEL\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_34348\\1040768143.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  baseline_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 07:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.649539</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.612819</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.583608</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Results:\n",
      "F1: 0.8853\n",
      "Precision: 0.8853\n",
      "Recall: 0.8853\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING BASELINE MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Initialize model\n",
    "baseline_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(ner_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "baseline_args = TrainingArguments(\n",
    "    output_dir=\"outputs/bert-ner-baseline\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "baseline_trainer = Trainer(\n",
    "    model=baseline_model,\n",
    "    args=baseline_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train\n",
    "baseline_trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "baseline_results = baseline_trainer.evaluate()\n",
    "print(f\"\\nBaseline Results:\")\n",
    "print(f\"F1: {baseline_results['eval_f1']:.4f}\")\n",
    "print(f\"Precision: {baseline_results['eval_precision']:.4f}\")\n",
    "print(f\"Recall: {baseline_results['eval_recall']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95daf6b-c17e-4674-8e91-d2fe16e3abd5",
   "metadata": {},
   "source": [
    "## 7. FINE-TUNING WITH BEST HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2046f559-c3f2-409b-bd96-93c12a734edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on your hyperparameter tuning results:\n",
    "best_hyperparams = {\n",
    "    \"full_ft\": {\n",
    "        \"learning_rate\": 4.358610256985791e-05,\n",
    "        \"batch_size\": 16,\n",
    "        \"method_name\": \"Full Fine-Tuning\"\n",
    "    },\n",
    "    \"lora\": {\n",
    "        \"learning_rate\": 2.220149951658828e-05,\n",
    "        \"r\": 16,\n",
    "        \"alpha\": 16,\n",
    "        \"dropout\": 0.015844640852335577,\n",
    "        \"batch_size\": 8,\n",
    "        \"method_name\": \"LoRA\"\n",
    "    },\n",
    "    \"partial_freeze\": {\n",
    "        \"freeze_pct\": 0.5,\n",
    "        \"learning_rate\": 3.2302001133689886e-05,\n",
    "        \"batch_size\": 16,\n",
    "        \"method_name\": \"Partial Freeze\"\n",
    "    }\n",
    "}\n",
    "\n",
    "results_summary = {\n",
    "    \"baseline\": baseline_results\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4923174-fe12-4d94-9e3e-602ac0601dff",
   "metadata": {},
   "source": [
    "## 7.1 FULL FINE-TUNING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f5ef2c0-334d-448a-b7e8-dda5f51f5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FULL FINE-TUNING WITH BEST PARAMETERS\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_34348\\42561499.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  ft_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 18:42, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.314200</td>\n",
       "      <td>0.582728</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "      <td>0.885307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.744800</td>\n",
       "      <td>0.489795</td>\n",
       "      <td>0.885277</td>\n",
       "      <td>0.885277</td>\n",
       "      <td>0.885277</td>\n",
       "      <td>0.885277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.666400</td>\n",
       "      <td>0.459513</td>\n",
       "      <td>0.889698</td>\n",
       "      <td>0.889698</td>\n",
       "      <td>0.889698</td>\n",
       "      <td>0.889698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.605900</td>\n",
       "      <td>0.437836</td>\n",
       "      <td>0.892026</td>\n",
       "      <td>0.892026</td>\n",
       "      <td>0.892026</td>\n",
       "      <td>0.892026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.524900</td>\n",
       "      <td>0.432223</td>\n",
       "      <td>0.891554</td>\n",
       "      <td>0.891554</td>\n",
       "      <td>0.891554</td>\n",
       "      <td>0.891554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Fine-Tuning Results:\n",
      "F1: 0.8916\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FULL FINE-TUNING WITH BEST PARAMETERS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create fresh model\n",
    "ft_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(ner_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# Training arguments with best hyperparameters\n",
    "ft_args = TrainingArguments(\n",
    "    output_dir=\"outputs/bert-ner-full-ft-final\",\n",
    "    max_steps=100,  # Fixed budget for fair comparison\n",
    "    per_device_train_batch_size=best_hyperparams[\"full_ft\"][\"batch_size\"],\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=best_hyperparams[\"full_ft\"][\"learning_rate\"],\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=20,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Train\n",
    "ft_trainer = Trainer(\n",
    "    model=ft_model,\n",
    "    args=ft_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "ft_trainer.train()\n",
    "ft_results = ft_trainer.evaluate()\n",
    "results_summary[\"full_ft\"] = ft_results\n",
    "\n",
    "print(f\"\\nFull Fine-Tuning Results:\")\n",
    "print(f\"F1: {ft_results['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af03c2c-992f-452c-b3c0-530de911c5a1",
   "metadata": {},
   "source": [
    "## 7.2 LoRA FINE-TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3b78fd6-dc6c-41ff-b2a4-64278bc19674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "LoRA FINE-TUNING WITH BEST PARAMETERS\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_34348\\2177920545.py:45: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForTokenClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 619,815 || all params: 109,541,454 || trainable%: 0.5658\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 08:45, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.837200</td>\n",
       "      <td>3.750606</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.729700</td>\n",
       "      <td>3.643124</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>0.014381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.642900</td>\n",
       "      <td>3.558876</td>\n",
       "      <td>0.031237</td>\n",
       "      <td>0.031237</td>\n",
       "      <td>0.031237</td>\n",
       "      <td>0.031237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.574600</td>\n",
       "      <td>3.504576</td>\n",
       "      <td>0.048447</td>\n",
       "      <td>0.048447</td>\n",
       "      <td>0.048447</td>\n",
       "      <td>0.048447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.544400</td>\n",
       "      <td>3.485232</td>\n",
       "      <td>0.056050</td>\n",
       "      <td>0.056050</td>\n",
       "      <td>0.056050</td>\n",
       "      <td>0.056050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LoRA Results:\n",
      "F1: 0.0560\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LoRA FINE-TUNING WITH BEST PARAMETERS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Create fresh model\n",
    "base_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(ner_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.TOKEN_CLS,\n",
    "    inference_mode=False,\n",
    "    r=best_hyperparams[\"lora\"][\"r\"],\n",
    "    lora_alpha=best_hyperparams[\"lora\"][\"alpha\"],\n",
    "    lora_dropout=best_hyperparams[\"lora\"][\"dropout\"],\n",
    "    target_modules=[\"query\", \"value\"],  # BERT-specific\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "lora_model = get_peft_model(base_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "# Training arguments\n",
    "lora_args = TrainingArguments(\n",
    "    output_dir=\"outputs/bert-ner-lora-final\",\n",
    "    max_steps=100,\n",
    "    per_device_train_batch_size=best_hyperparams[\"lora\"][\"batch_size\"],\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=best_hyperparams[\"lora\"][\"learning_rate\"],\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=20,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Train\n",
    "lora_trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=lora_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "lora_trainer.train()\n",
    "lora_results = lora_trainer.evaluate()\n",
    "results_summary[\"lora\"] = lora_results\n",
    "\n",
    "print(f\"\\nLoRA Results:\")\n",
    "print(f\"F1: {lora_results['eval_f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699308d0-094b-41a8-b33a-7a1f43129b2a",
   "metadata": {},
   "source": [
    "## 7.3 PARTIAL FREEZE FINE-TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "827e90ed-fcb3-469e-bcfb-916b10583c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PARTIAL FREEZE FINE-TUNING WITH BEST PARAMETERS\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_34348\\160557065.py:45: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  freeze_trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 23,867,175 / 108,921,639 (21.91%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 15:09, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.651700</td>\n",
       "      <td>3.545870</td>\n",
       "      <td>0.057612</td>\n",
       "      <td>0.057612</td>\n",
       "      <td>0.057612</td>\n",
       "      <td>0.057612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.487800</td>\n",
       "      <td>3.393096</td>\n",
       "      <td>0.159840</td>\n",
       "      <td>0.159840</td>\n",
       "      <td>0.159840</td>\n",
       "      <td>0.159840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.365600</td>\n",
       "      <td>3.281527</td>\n",
       "      <td>0.281340</td>\n",
       "      <td>0.281340</td>\n",
       "      <td>0.281340</td>\n",
       "      <td>0.281340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.284500</td>\n",
       "      <td>3.212695</td>\n",
       "      <td>0.364148</td>\n",
       "      <td>0.364148</td>\n",
       "      <td>0.364148</td>\n",
       "      <td>0.364148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.230400</td>\n",
       "      <td>3.188612</td>\n",
       "      <td>0.394206</td>\n",
       "      <td>0.394206</td>\n",
       "      <td>0.394206</td>\n",
       "      <td>0.394206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Partial Freeze Results:\n",
      "F1: 0.3942\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PARTIAL FREEZE FINE-TUNING WITH BEST PARAMETERS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create fresh model\n",
    "freeze_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(ner_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# Freeze bottom 50% of layers\n",
    "freeze_pct = best_hyperparams[\"partial_freeze\"][\"freeze_pct\"]\n",
    "num_layers = len([n for n, _ in freeze_model.named_parameters() if \"encoder.layer\" in n]) // 2\n",
    "freeze_until = int(num_layers * freeze_pct)\n",
    "\n",
    "for name, param in freeze_model.named_parameters():\n",
    "    if \"encoder.layer\" in name:\n",
    "        layer_num = int(name.split(\".\")[3])\n",
    "        if layer_num < freeze_until:\n",
    "            param.requires_grad = False\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_params = sum(p.numel() for p in freeze_model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in freeze_model.parameters())\n",
    "print(f\"Trainable parameters: {trainable_params:,} / {total_params:,} ({trainable_params/total_params*100:.2f}%)\")\n",
    "\n",
    "# Training arguments\n",
    "freeze_args = TrainingArguments(\n",
    "    output_dir=\"outputs/bert-ner-freeze-final\",\n",
    "    max_steps=100,\n",
    "    per_device_train_batch_size=best_hyperparams[\"partial_freeze\"][\"batch_size\"],\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=best_hyperparams[\"partial_freeze\"][\"learning_rate\"],\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=20,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Train\n",
    "freeze_trainer = Trainer(\n",
    "    model=freeze_model,\n",
    "    args=freeze_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "freeze_trainer.train()\n",
    "freeze_results = freeze_trainer.evaluate()\n",
    "results_summary[\"partial_freeze\"] = freeze_results\n",
    "\n",
    "print(f\"\\nPartial Freeze Results:\")\n",
    "print(f\"F1: {freeze_results['eval_f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926a17fd-16f9-404e-8ccf-e07a414d7be0",
   "metadata": {},
   "source": [
    "## 8. RESULTS COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f39c796-5fc8-4355-980a-604e60841ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RESULTS COMPARISON\n",
      "==================================================\n",
      "        Method    F1  Precision  Recall  Accuracy\n",
      "      Baseline 88.53      88.53   88.53     88.53\n",
      "       Full Ft 89.16      89.16   89.16     89.16\n",
      "          Lora  5.60       5.60    5.60      5.60\n",
      "Partial Freeze 39.42      39.42   39.42     39.42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESULTS COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create comparison table\n",
    "import pandas as pd\n",
    "\n",
    "comparison_data = []\n",
    "for method, results in results_summary.items():\n",
    "    comparison_data.append({\n",
    "        \"Method\": method.replace(\"_\", \" \").title(),\n",
    "        \"F1\": results.get(\"eval_f1\", 0) * 100,\n",
    "        \"Precision\": results.get(\"eval_precision\", 0) * 100,\n",
    "        \"Recall\": results.get(\"eval_recall\", 0) * 100,\n",
    "        \"Accuracy\": results.get(\"eval_accuracy\", 0) * 100,\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.round(2)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36460f2-1d1c-4ad3-9cd0-430eb62f6a3c",
   "metadata": {},
   "source": [
    "## 9. VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfa9117c-5417-439d-b59c-5e63802f6411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plot for F1 scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "methods = comparison_df[\"Method\"].tolist()\n",
    "f1_scores = comparison_df[\"F1\"].tolist()\n",
    "\n",
    "bars = plt.bar(methods, f1_scores, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "plt.ylabel('F1 Score (%)', fontsize=12)\n",
    "plt.title('BERT NER Performance Comparison', fontsize=14)\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, score in zip(bars, f1_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "             f'{score:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/bert_ner_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c527174d-89e7-463c-b972-a506bcb37aa3",
   "metadata": {},
   "source": [
    "## 10. TEST SET EVALUATION (FINAL MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "539a8921-be3a-471e-b61f-5cd6f170e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FINAL TEST SET EVALUATION\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51bb1dda64249ee8b2326a5a0a81eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated predictions for 731 test examples\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL TEST SET EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use the best performing model (full fine-tuning based on your results)\n",
    "# Note: For test set, we need to handle the different structure\n",
    "test_examples = []\n",
    "for doc in test_docs:\n",
    "    # Test docs have different structure\n",
    "    text = doc.get(\"document\", doc.get(\"doc\", \"\"))\n",
    "    if text:\n",
    "        test_examples.append({\n",
    "            \"doc\": text,\n",
    "            \"entities\": [],  # No labels in test set\n",
    "            \"id\": doc.get(\"id\", \"\")\n",
    "        })\n",
    "\n",
    "hf_test_for_inference = Dataset.from_list(test_examples)\n",
    "\n",
    "# Tokenize test set\n",
    "tokenized_test = hf_test_for_inference.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=hf_test_for_inference.column_names\n",
    ")\n",
    "\n",
    "# Get predictions from best model\n",
    "test_predictions = ft_trainer.predict(tokenized_test)\n",
    "predictions = np.argmax(test_predictions.predictions, axis=-1)\n",
    "\n",
    "# Convert predictions back to labels\n",
    "predicted_labels = []\n",
    "for pred_seq in predictions:\n",
    "    labels = [id2label[p] for p in pred_seq if p != -100]\n",
    "    predicted_labels.append(labels)\n",
    "\n",
    "print(f\"Generated predictions for {len(predicted_labels)} test examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc1ef4-c26f-4de8-bf54-a38bdc3879ea",
   "metadata": {},
   "source": [
    "## 11. SAVE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9a3bb3e-23fe-487f-9b48-b4e4f700bd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… All results saved to outputs/\n",
      "ðŸ“Š Visualization saved as bert_ner_comparison.png\n",
      "ðŸ’¾ Best model saved to outputs/bert-ner-best-model/\n"
     ]
    }
   ],
   "source": [
    "# Save comparison table\n",
    "comparison_df.to_csv(\"outputs/bert_ner_results.csv\", index=False)\n",
    "\n",
    "# Save best model\n",
    "ft_trainer.save_model(\"outputs/bert-ner-best-model\")\n",
    "tokenizer.save_pretrained(\"outputs/bert-ner-best-model\")\n",
    "\n",
    "# Save predictions\n",
    "import json\n",
    "with open(\"outputs/bert_ner_test_predictions.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"predictions\": predicted_labels[:10],  # Sample\n",
    "        \"model\": \"bert-base-uncased\",\n",
    "        \"task\": \"NER\",\n",
    "        \"best_f1\": float(ft_results['eval_f1'])\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ… All results saved to outputs/\")\n",
    "print(\"ðŸ“Š Visualization saved as bert_ner_comparison.png\")\n",
    "print(\"ðŸ’¾ Best model saved to outputs/bert-ner-best-model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd851544-22a3-48e2-be25-90abcac0daec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
