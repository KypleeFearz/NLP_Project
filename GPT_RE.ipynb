{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d462da-e50a-4b1c-a860-9d3b54cd14ba",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8411ec0-5062-4e20-b705-63edc0163500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481ed12-27f5-4991-8020-102e44898f77",
   "metadata": {},
   "source": [
    "## 2. Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d34dc27-9c74-4b1e-a814-5b2480b87c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path(r\"C:\\Users\\nmilo\\OneDrive\\Desktop\\Master\\Semester2\\NLP\\project\\dataset\\train\")\n",
    "DEV_DIR = Path(r\"C:\\Users\\nmilo\\OneDrive\\Desktop\\Master\\Semester2\\NLP\\project\\dataset\\dev\")\n",
    "TEST_DIR = Path(r\"C:\\Users\\nmilo\\OneDrive\\Desktop\\Master\\Semester2\\NLP\\project\\dataset\\test\")\n",
    "\n",
    "assert TRAIN_DIR.exists(), f\"Train directory not found: {TRAIN_DIR}\"\n",
    "assert DEV_DIR.exists(), f\"Dev directory not found: {DEV_DIR}\"\n",
    "assert TEST_DIR.exists(), f\"Test directory not found: {TEST_DIR}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48e7160-1485-4ce7-bb27-a3c5b08d5465",
   "metadata": {},
   "source": [
    "## 3. Load DocIE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf837b15-f6ac-4b85-9d96-c3b007354e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded documents - Train: 51, Dev: 23, Test: 248\n"
     ]
    }
   ],
   "source": [
    "def load_docie_docs(folder: Path, recursive: bool = False):\n",
    "    \"\"\"Load DocIE documents from JSON files.\"\"\"\n",
    "    docs = []\n",
    "    pattern = \"**/*.json\" if recursive else \"*.json\"\n",
    "    for file in folder.glob(pattern):\n",
    "        data = json.loads(file.read_text(encoding=\"utf-8\"))\n",
    "        if isinstance(data, list):\n",
    "            docs.extend(data)\n",
    "        else:\n",
    "            docs.append(data)\n",
    "    return docs\n",
    "\n",
    "train_docs = load_docie_docs(TRAIN_DIR)\n",
    "dev_docs = load_docie_docs(DEV_DIR)\n",
    "test_docs = load_docie_docs(TEST_DIR, recursive=True)\n",
    "\n",
    "print(f\"Loaded documents - Train: {len(train_docs)}, Dev: {len(dev_docs)}, Test: {len(test_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e74b1-649a-423c-9744-d4b7291b98fb",
   "metadata": {},
   "source": [
    "## 4. Prepare Relation Extraction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0193d6dc-2b93-4479-9374-6b1ae365f191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE Examples - Train: 1222, Dev: 606, Test: 0\n"
     ]
    }
   ],
   "source": [
    "def create_re_examples(docs, split_name):\n",
    "    \"\"\"Create relation extraction examples from DocIE documents.\"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        if not doc.get(\"triples\") or not doc.get(\"entities\"):\n",
    "            continue\n",
    "            \n",
    "        text = doc.get(\"doc\") or doc.get(\"document\")\n",
    "        if not text:\n",
    "            continue\n",
    "            \n",
    "        entity_mentions = [ent[\"mentions\"][0] for ent in doc[\"entities\"] if ent.get(\"mentions\")]\n",
    "        \n",
    "        # Create positive examples\n",
    "        for triple in doc[\"triples\"]:\n",
    "            examples.append({\n",
    "                \"text\": f\"{triple['head']} [SEP] {triple['tail']} [SEP] {text}\",\n",
    "                \"label\": triple[\"relation\"],\n",
    "                \"split\": split_name\n",
    "            })\n",
    "            \n",
    "        # Create negative examples\n",
    "        positive_pairs = {(triple[\"head\"], triple[\"tail\"]) for triple in doc[\"triples\"]}\n",
    "        negative_count = 0\n",
    "        max_attempts = len(doc[\"triples\"]) * 10\n",
    "        attempts = 0\n",
    "        \n",
    "        while negative_count < len(doc[\"triples\"]) and attempts < max_attempts:\n",
    "            attempts += 1\n",
    "            if len(entity_mentions) < 2:\n",
    "                break\n",
    "                \n",
    "            import random\n",
    "            head, tail = random.sample(entity_mentions, 2)\n",
    "            if (head, tail) not in positive_pairs and (tail, head) not in positive_pairs:\n",
    "                examples.append({\n",
    "                    \"text\": f\"{head} [SEP] {tail} [SEP] {text}\",\n",
    "                    \"label\": \"no_relation\",\n",
    "                    \"split\": split_name\n",
    "                })\n",
    "                negative_count += 1\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Create examples\n",
    "train_examples = create_re_examples(train_docs, \"train\")\n",
    "dev_examples = create_re_examples(dev_docs, \"dev\")\n",
    "test_examples = create_re_examples(test_docs, \"test\")\n",
    "\n",
    "print(f\"RE Examples - Train: {len(train_examples)}, Dev: {len(dev_examples)}, Test: {len(test_examples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e55db-e593-454a-a544-54f703f987c6",
   "metadata": {},
   "source": [
    "## 5. Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b89cc44b-a39d-454c-b44f-f59433cb04e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relation types: 76\n",
      "\n",
      "Label distribution in training data:\n",
      "  no_relation: 611\n",
      "  HasPart: 82\n",
      "  HasEffect: 67\n",
      "  DiplomaticRelation: 45\n",
      "  LocatedIn: 44\n",
      "  InterestedIn: 38\n",
      "  OwnerOf: 32\n",
      "  NominatedFor: 25\n",
      "  SaidToBeTheSameAs: 25\n",
      "  PartOf: 18\n"
     ]
    }
   ],
   "source": [
    "# Get all unique labels\n",
    "all_labels = sorted(set(ex[\"label\"] for ex in train_examples + dev_examples))\n",
    "label2id = {label: i for i, label in enumerate(all_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "print(f\"Number of relation types: {len(all_labels)}\")\n",
    "\n",
    "# Analyze label distribution\n",
    "label_counts = Counter(ex[\"label\"] for ex in train_examples)\n",
    "print(\"\\nLabel distribution in training data:\")\n",
    "for label, count in label_counts.most_common(10):\n",
    "    print(f\"  {label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee02d17-23a0-4ed7-b8ad-22835a5bee5a",
   "metadata": {},
   "source": [
    "## 6. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64cb5ef6-1ebc-4f74-a1de-01ca0fbffc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27eea06b17b7443a9325c79404af7245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1222 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9975a6b826334838ac0c8ffc3d34294c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/606 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6f07aed3c34acda70e97f2568102a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1222 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac0d11b7ff84b798d3ca7f905693a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/606 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized datasets - Train: 1222, Dev: 606\n"
     ]
    }
   ],
   "source": [
    "model_name = \"EleutherAI/gpt-neo-125M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Add padding token for GPT-Neo\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_list(train_examples)\n",
    "dev_dataset = Dataset.from_list(dev_examples)\n",
    "\n",
    "# Tokenize\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\", \"split\"]\n",
    ")\n",
    "\n",
    "dev_dataset = dev_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\", \"split\"]\n",
    ")\n",
    "\n",
    "# Add labels\n",
    "train_dataset = train_dataset.map(lambda x: {\"labels\": label2id[x[\"label\"]]})\n",
    "dev_dataset = dev_dataset.map(lambda x: {\"labels\": label2id[x[\"label\"]]})\n",
    "\n",
    "# Remove original label column\n",
    "train_dataset = train_dataset.remove_columns([\"label\"])\n",
    "dev_dataset = dev_dataset.remove_columns([\"label\"])\n",
    "\n",
    "# Set format\n",
    "train_dataset.set_format(\"torch\")\n",
    "dev_dataset.set_format(\"torch\")\n",
    "\n",
    "print(f\"Tokenized datasets - Train: {len(train_dataset)}, Dev: {len(dev_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeaa2a1-a3db-4f46-bf42-674130f38c01",
   "metadata": {},
   "source": [
    "## 7. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18cb1f4c-956b-4393-a2ba-91b0aa5996f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted', zero_division=0\n",
    "    )\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3729d03-01a4-448c-a116-ff5b33a3ffa5",
   "metadata": {},
   "source": [
    "## 8. Baseline Model (3 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b36a0df-d503-46ce-a845-a9e71107671b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training baseline model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\2493357242.py:32: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='459' max='459' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [459/459 54:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.532200</td>\n",
       "      <td>3.554785</td>\n",
       "      <td>0.247587</td>\n",
       "      <td>0.339934</td>\n",
       "      <td>0.286333</td>\n",
       "      <td>0.339934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.565700</td>\n",
       "      <td>3.296500</td>\n",
       "      <td>0.258413</td>\n",
       "      <td>0.344884</td>\n",
       "      <td>0.293314</td>\n",
       "      <td>0.344884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.884400</td>\n",
       "      <td>3.313860</td>\n",
       "      <td>0.266385</td>\n",
       "      <td>0.354785</td>\n",
       "      <td>0.299413</td>\n",
       "      <td>0.354785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline F1: 0.2994\n",
      "Baseline Accuracy: 0.3548\n"
     ]
    }
   ],
   "source": [
    "def train_baseline():\n",
    "    \"\"\"Train GPT-Neo baseline for relation extraction.\"\"\"\n",
    "    print(\"Training baseline model...\")\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(all_labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "    \n",
    "    # Resize embeddings for padding token\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"outputs/gpt-neo-re-baseline\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=16,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=50,\n",
    "        learning_rate=2e-5,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_f1\",\n",
    "        fp16=torch.cuda.is_available(),\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    \n",
    "    return trainer, metrics\n",
    "\n",
    "baseline_trainer, baseline_metrics = train_baseline()\n",
    "print(f\"\\nBaseline F1: {baseline_metrics['eval_f1']:.4f}\")\n",
    "print(f\"Baseline Accuracy: {baseline_metrics['eval_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd032cf-4812-4cf4-a6c7-bfd6a4870c98",
   "metadata": {},
   "source": [
    "## 9. Hyperparameter Tuning - Full Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a32cb567-7a24-4e7d-9376-2e29114e48a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 03:16:16,165] A new study created in memory with name: no-name-fe64bfb4-3da2-4c40-b48e-0c067e181fb2\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\692611427.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 34:47, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.658500</td>\n",
       "      <td>3.817922</td>\n",
       "      <td>0.263757</td>\n",
       "      <td>0.275578</td>\n",
       "      <td>0.268711</td>\n",
       "      <td>0.275578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.170800</td>\n",
       "      <td>3.532870</td>\n",
       "      <td>0.249077</td>\n",
       "      <td>0.445545</td>\n",
       "      <td>0.319527</td>\n",
       "      <td>0.445545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.244700</td>\n",
       "      <td>3.430428</td>\n",
       "      <td>0.254960</td>\n",
       "      <td>0.424092</td>\n",
       "      <td>0.318463</td>\n",
       "      <td>0.424092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.021500</td>\n",
       "      <td>3.373299</td>\n",
       "      <td>0.257028</td>\n",
       "      <td>0.422442</td>\n",
       "      <td>0.319600</td>\n",
       "      <td>0.422442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.747700</td>\n",
       "      <td>3.351844</td>\n",
       "      <td>0.254319</td>\n",
       "      <td>0.437294</td>\n",
       "      <td>0.321602</td>\n",
       "      <td>0.437294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 03:54:11,236] Trial 0 finished with value: 0.32160194174757284 and parameters: {'learning_rate': 1.2522178870528406e-05, 'batch_size': 16}. Best is trial 0 with value: 0.32160194174757284.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\692611427.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 23:36, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.019200</td>\n",
       "      <td>3.633945</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.462046</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.462046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.275911</td>\n",
       "      <td>0.244526</td>\n",
       "      <td>0.442244</td>\n",
       "      <td>0.314924</td>\n",
       "      <td>0.442244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.453800</td>\n",
       "      <td>3.184544</td>\n",
       "      <td>0.257838</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.324737</td>\n",
       "      <td>0.455446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.589800</td>\n",
       "      <td>3.151311</td>\n",
       "      <td>0.247824</td>\n",
       "      <td>0.387789</td>\n",
       "      <td>0.301169</td>\n",
       "      <td>0.387789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.595700</td>\n",
       "      <td>3.135319</td>\n",
       "      <td>0.247233</td>\n",
       "      <td>0.386139</td>\n",
       "      <td>0.300230</td>\n",
       "      <td>0.386139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 04:20:36,991] Trial 1 finished with value: 0.30022985016017756 and parameters: {'learning_rate': 3.5543473867698866e-05, 'batch_size': 8}. Best is trial 0 with value: 0.32160194174757284.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\692611427.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 17:21, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.174400</td>\n",
       "      <td>4.377393</td>\n",
       "      <td>0.266525</td>\n",
       "      <td>0.089109</td>\n",
       "      <td>0.130525</td>\n",
       "      <td>0.089109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.143400</td>\n",
       "      <td>3.788192</td>\n",
       "      <td>0.268266</td>\n",
       "      <td>0.301980</td>\n",
       "      <td>0.283948</td>\n",
       "      <td>0.301980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.769300</td>\n",
       "      <td>3.642563</td>\n",
       "      <td>0.260820</td>\n",
       "      <td>0.377888</td>\n",
       "      <td>0.308625</td>\n",
       "      <td>0.377888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.257500</td>\n",
       "      <td>3.591521</td>\n",
       "      <td>0.257829</td>\n",
       "      <td>0.407591</td>\n",
       "      <td>0.315857</td>\n",
       "      <td>0.407591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.063800</td>\n",
       "      <td>3.579115</td>\n",
       "      <td>0.255670</td>\n",
       "      <td>0.409241</td>\n",
       "      <td>0.314721</td>\n",
       "      <td>0.409241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 02:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 04:40:29,543] Trial 2 finished with value: 0.3147208121827411 and parameters: {'learning_rate': 1.046558766448581e-05, 'batch_size': 4}. Best is trial 0 with value: 0.32160194174757284.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\692611427.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 34:57, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.367200</td>\n",
       "      <td>3.601080</td>\n",
       "      <td>0.255670</td>\n",
       "      <td>0.409241</td>\n",
       "      <td>0.314721</td>\n",
       "      <td>0.409241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.985600</td>\n",
       "      <td>3.431005</td>\n",
       "      <td>0.250452</td>\n",
       "      <td>0.457096</td>\n",
       "      <td>0.323598</td>\n",
       "      <td>0.457096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.033000</td>\n",
       "      <td>3.312682</td>\n",
       "      <td>0.256286</td>\n",
       "      <td>0.437294</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.437294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.785500</td>\n",
       "      <td>3.239629</td>\n",
       "      <td>0.252799</td>\n",
       "      <td>0.447195</td>\n",
       "      <td>0.323004</td>\n",
       "      <td>0.447195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.466500</td>\n",
       "      <td>3.221342</td>\n",
       "      <td>0.249094</td>\n",
       "      <td>0.453795</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.453795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 05:18:31,110] Trial 3 finished with value: 0.32163742690058483 and parameters: {'learning_rate': 1.7493417877719413e-05, 'batch_size': 16}. Best is trial 3 with value: 0.32163742690058483.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\692611427.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 23:33, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.985400</td>\n",
       "      <td>3.923687</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.193069</td>\n",
       "      <td>0.210811</td>\n",
       "      <td>0.193069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.455900</td>\n",
       "      <td>3.555656</td>\n",
       "      <td>0.242204</td>\n",
       "      <td>0.384488</td>\n",
       "      <td>0.297194</td>\n",
       "      <td>0.384488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.946000</td>\n",
       "      <td>3.487400</td>\n",
       "      <td>0.244554</td>\n",
       "      <td>0.407591</td>\n",
       "      <td>0.305693</td>\n",
       "      <td>0.407591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.250100</td>\n",
       "      <td>3.453459</td>\n",
       "      <td>0.245059</td>\n",
       "      <td>0.409241</td>\n",
       "      <td>0.306551</td>\n",
       "      <td>0.409241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.118200</td>\n",
       "      <td>3.441868</td>\n",
       "      <td>0.244511</td>\n",
       "      <td>0.404290</td>\n",
       "      <td>0.304726</td>\n",
       "      <td>0.404290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 05:44:55,006] Trial 4 finished with value: 0.304726368159204 and parameters: {'learning_rate': 1.1466017907330151e-05, 'batch_size': 8}. Best is trial 3 with value: 0.32163742690058483.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\692611427.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 34:53, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.039200</td>\n",
       "      <td>3.561223</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.486799</td>\n",
       "      <td>0.330347</td>\n",
       "      <td>0.486799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.757100</td>\n",
       "      <td>3.257687</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.322807</td>\n",
       "      <td>0.455446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.743500</td>\n",
       "      <td>3.123118</td>\n",
       "      <td>0.253886</td>\n",
       "      <td>0.485149</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.485149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.473700</td>\n",
       "      <td>3.060062</td>\n",
       "      <td>0.261860</td>\n",
       "      <td>0.471947</td>\n",
       "      <td>0.335603</td>\n",
       "      <td>0.471947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.130700</td>\n",
       "      <td>3.052176</td>\n",
       "      <td>0.251286</td>\n",
       "      <td>0.483498</td>\n",
       "      <td>0.330700</td>\n",
       "      <td>0.483498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 06:22:53,873] Trial 5 finished with value: 0.3306997742663657 and parameters: {'learning_rate': 2.903968752043959e-05, 'batch_size': 16}. Best is trial 5 with value: 0.3306997742663657.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\692611427.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 23:34, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.049800</td>\n",
       "      <td>3.654872</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.462046</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.462046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.027600</td>\n",
       "      <td>3.293710</td>\n",
       "      <td>0.244526</td>\n",
       "      <td>0.442244</td>\n",
       "      <td>0.314924</td>\n",
       "      <td>0.442244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.476200</td>\n",
       "      <td>3.201474</td>\n",
       "      <td>0.259495</td>\n",
       "      <td>0.457096</td>\n",
       "      <td>0.325662</td>\n",
       "      <td>0.457096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.618100</td>\n",
       "      <td>3.162680</td>\n",
       "      <td>0.248544</td>\n",
       "      <td>0.394389</td>\n",
       "      <td>0.303652</td>\n",
       "      <td>0.394389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.614500</td>\n",
       "      <td>3.147229</td>\n",
       "      <td>0.247824</td>\n",
       "      <td>0.387789</td>\n",
       "      <td>0.301169</td>\n",
       "      <td>0.387789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 06:49:18,231] Trial 6 finished with value: 0.30116946869956507 and parameters: {'learning_rate': 3.393735945460472e-05, 'batch_size': 8}. Best is trial 5 with value: 0.3306997742663657.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\692611427.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 23:26, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.615200</td>\n",
       "      <td>3.672877</td>\n",
       "      <td>0.263279</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.309783</td>\n",
       "      <td>0.376238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.403400</td>\n",
       "      <td>3.535247</td>\n",
       "      <td>0.250444</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>0.325635</td>\n",
       "      <td>0.465347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.806900</td>\n",
       "      <td>3.436536</td>\n",
       "      <td>0.246454</td>\n",
       "      <td>0.458746</td>\n",
       "      <td>0.320646</td>\n",
       "      <td>0.458746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.900800</td>\n",
       "      <td>3.382913</td>\n",
       "      <td>0.249550</td>\n",
       "      <td>0.457096</td>\n",
       "      <td>0.322844</td>\n",
       "      <td>0.457096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.923800</td>\n",
       "      <td>3.361806</td>\n",
       "      <td>0.254190</td>\n",
       "      <td>0.450495</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.450495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 07:15:33,402] Trial 7 finished with value: 0.325 and parameters: {'learning_rate': 1.740905511019205e-05, 'batch_size': 8}. Best is trial 5 with value: 0.3306997742663657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best FT params: {'learning_rate': 2.903968752043959e-05, 'batch_size': 16}\n",
      "Best FT F1: 0.3307\n"
     ]
    }
   ],
   "source": [
    "def ft_objective(trial):\n",
    "    \"\"\"Optuna objective for full fine-tuning.\"\"\"\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(all_labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"tmp/gpt-neo-re-ft-{trial.number}\",\n",
    "        max_steps=100,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size * 2,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=20,\n",
    "        save_strategy=\"no\",\n",
    "        learning_rate=lr,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        logging_steps=20,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer.evaluate()[\"eval_f1\"]\n",
    "\n",
    "# Run optimization\n",
    "study_ft = optuna.create_study(direction=\"maximize\")\n",
    "study_ft.optimize(ft_objective, n_trials=8)\n",
    "\n",
    "print(f\"Best FT params: {study_ft.best_params}\")\n",
    "print(f\"Best FT F1: {study_ft.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6fd21-ec64-46c8-ab46-26eda0b80c8f",
   "metadata": {},
   "source": [
    "## 10. Hyperparameter Tuning - LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b156c0b2-2a73-4745-b593-f6dcd6f7e315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 07:15:33,412] A new study created in memory with name: no-name-9dc1b527-75f8-4058-b4b3-27398cec792d\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1367073759.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 21:50, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.730100</td>\n",
       "      <td>5.477643</td>\n",
       "      <td>0.409156</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019985</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.588100</td>\n",
       "      <td>5.411362</td>\n",
       "      <td>0.408685</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.382900</td>\n",
       "      <td>5.354878</td>\n",
       "      <td>0.408685</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.262900</td>\n",
       "      <td>5.314739</td>\n",
       "      <td>0.342018</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019848</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.315600</td>\n",
       "      <td>5.300470</td>\n",
       "      <td>0.342018</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019848</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 07:40:10,990] Trial 0 finished with value: 0.019847511040493544 and parameters: {'learning_rate': 1.435319760989475e-05, 'r': 16, 'alpha': 32, 'dropout': 0.1782883738588033, 'batch_size': 8}. Best is trial 0 with value: 0.019847511040493544.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1367073759.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 32:11, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.958400</td>\n",
       "      <td>5.895634</td>\n",
       "      <td>0.019095</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.004950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.844600</td>\n",
       "      <td>5.827048</td>\n",
       "      <td>0.019095</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.004950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.737600</td>\n",
       "      <td>5.767720</td>\n",
       "      <td>0.018710</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>0.004950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.643200</td>\n",
       "      <td>5.728831</td>\n",
       "      <td>0.015839</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>0.004950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.717000</td>\n",
       "      <td>5.714076</td>\n",
       "      <td>0.015839</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>0.004950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 08:15:31,438] Trial 1 finished with value: 0.007058189430213867 and parameters: {'learning_rate': 1.2739486555815162e-05, 'r': 16, 'alpha': 32, 'dropout': 0.022976803823493975, 'batch_size': 16}. Best is trial 0 with value: 0.019847511040493544.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1367073759.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 16:28, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.587100</td>\n",
       "      <td>5.370897</td>\n",
       "      <td>0.134048</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>0.008251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.857100</td>\n",
       "      <td>4.944454</td>\n",
       "      <td>0.211991</td>\n",
       "      <td>0.021452</td>\n",
       "      <td>0.031775</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.527800</td>\n",
       "      <td>4.545466</td>\n",
       "      <td>0.245459</td>\n",
       "      <td>0.092409</td>\n",
       "      <td>0.130721</td>\n",
       "      <td>0.092409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.493000</td>\n",
       "      <td>4.261338</td>\n",
       "      <td>0.247121</td>\n",
       "      <td>0.132013</td>\n",
       "      <td>0.170633</td>\n",
       "      <td>0.132013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.905900</td>\n",
       "      <td>4.170292</td>\n",
       "      <td>0.259729</td>\n",
       "      <td>0.183168</td>\n",
       "      <td>0.213870</td>\n",
       "      <td>0.183168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 02:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 08:34:33,956] Trial 2 finished with value: 0.21386961516707872 and parameters: {'learning_rate': 6.431809566092199e-05, 'r': 16, 'alpha': 32, 'dropout': 0.05853641210915119, 'batch_size': 4}. Best is trial 2 with value: 0.21386961516707872.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1367073759.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 32:07, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.359200</td>\n",
       "      <td>4.826664</td>\n",
       "      <td>0.213711</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.016783</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.650100</td>\n",
       "      <td>3.305587</td>\n",
       "      <td>0.265350</td>\n",
       "      <td>0.359736</td>\n",
       "      <td>0.305196</td>\n",
       "      <td>0.359736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.048300</td>\n",
       "      <td>3.105070</td>\n",
       "      <td>0.269516</td>\n",
       "      <td>0.410891</td>\n",
       "      <td>0.325176</td>\n",
       "      <td>0.410891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.677900</td>\n",
       "      <td>3.090599</td>\n",
       "      <td>0.260139</td>\n",
       "      <td>0.371287</td>\n",
       "      <td>0.304671</td>\n",
       "      <td>0.371287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.643700</td>\n",
       "      <td>3.073749</td>\n",
       "      <td>0.261458</td>\n",
       "      <td>0.374587</td>\n",
       "      <td>0.306660</td>\n",
       "      <td>0.374587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 09:09:52,432] Trial 3 finished with value: 0.3066599841284176 and parameters: {'learning_rate': 0.00012046864944909521, 'r': 16, 'alpha': 32, 'dropout': 0.25181917777846907, 'batch_size': 16}. Best is trial 3 with value: 0.3066599841284176.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1367073759.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 32:09, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.918300</td>\n",
       "      <td>3.572415</td>\n",
       "      <td>0.241090</td>\n",
       "      <td>0.379538</td>\n",
       "      <td>0.294872</td>\n",
       "      <td>0.379538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.694700</td>\n",
       "      <td>3.483599</td>\n",
       "      <td>0.267086</td>\n",
       "      <td>0.372937</td>\n",
       "      <td>0.310609</td>\n",
       "      <td>0.372937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.579000</td>\n",
       "      <td>3.372897</td>\n",
       "      <td>0.259760</td>\n",
       "      <td>0.343234</td>\n",
       "      <td>0.294170</td>\n",
       "      <td>0.343234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.209700</td>\n",
       "      <td>3.312651</td>\n",
       "      <td>0.253964</td>\n",
       "      <td>0.376238</td>\n",
       "      <td>0.302881</td>\n",
       "      <td>0.376238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.954100</td>\n",
       "      <td>3.297530</td>\n",
       "      <td>0.257018</td>\n",
       "      <td>0.410891</td>\n",
       "      <td>0.316169</td>\n",
       "      <td>0.410891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 09:45:11,153] Trial 4 finished with value: 0.31616916363125164 and parameters: {'learning_rate': 0.00046162295786666236, 'r': 8, 'alpha': 16, 'dropout': 0.10221488340598575, 'batch_size': 16}. Best is trial 4 with value: 0.31616916363125164.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1367073759.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 16:25, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.806300</td>\n",
       "      <td>5.671512</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.438400</td>\n",
       "      <td>5.643305</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.412300</td>\n",
       "      <td>5.621498</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.196000</td>\n",
       "      <td>5.605853</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.700700</td>\n",
       "      <td>5.600922</td>\n",
       "      <td>0.010257</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 02:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 10:04:11,017] Trial 5 finished with value: 0.004226711087184368 and parameters: {'learning_rate': 1.0748930810703996e-05, 'r': 16, 'alpha': 16, 'dropout': 0.1947894832813145, 'batch_size': 4}. Best is trial 4 with value: 0.31616916363125164.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1367073759.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 32:10, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.670100</td>\n",
       "      <td>3.598578</td>\n",
       "      <td>0.254990</td>\n",
       "      <td>0.260726</td>\n",
       "      <td>0.256027</td>\n",
       "      <td>0.260726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.849400</td>\n",
       "      <td>3.154088</td>\n",
       "      <td>0.266086</td>\n",
       "      <td>0.374587</td>\n",
       "      <td>0.310118</td>\n",
       "      <td>0.374587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.721400</td>\n",
       "      <td>3.115199</td>\n",
       "      <td>0.270886</td>\n",
       "      <td>0.341584</td>\n",
       "      <td>0.301945</td>\n",
       "      <td>0.341584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.372300</td>\n",
       "      <td>3.042741</td>\n",
       "      <td>0.263784</td>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.305934</td>\n",
       "      <td>0.366337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.193100</td>\n",
       "      <td>3.026380</td>\n",
       "      <td>0.263083</td>\n",
       "      <td>0.384488</td>\n",
       "      <td>0.311481</td>\n",
       "      <td>0.384488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 10:39:31,390] Trial 6 finished with value: 0.31148086555454363 and parameters: {'learning_rate': 0.00026741883933400996, 'r': 8, 'alpha': 16, 'dropout': 0.2831218733958956, 'batch_size': 16}. Best is trial 4 with value: 0.31616916363125164.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1367073759.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 21:52, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.577100</td>\n",
       "      <td>5.565613</td>\n",
       "      <td>0.009061</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.120700</td>\n",
       "      <td>5.412537</td>\n",
       "      <td>0.134061</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>0.008251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.192200</td>\n",
       "      <td>5.264652</td>\n",
       "      <td>0.109061</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>0.008251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.164900</td>\n",
       "      <td>5.157625</td>\n",
       "      <td>0.175727</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.010613</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.709300</td>\n",
       "      <td>5.118991</td>\n",
       "      <td>0.196561</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>0.013787</td>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 11:04:11,650] Trial 7 finished with value: 0.013786994097766332 and parameters: {'learning_rate': 2.7186387143190654e-05, 'r': 4, 'alpha': 32, 'dropout': 0.04878265369032201, 'batch_size': 8}. Best is trial 4 with value: 0.31616916363125164.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LoRA params: {'learning_rate': 0.00046162295786666236, 'r': 8, 'alpha': 16, 'dropout': 0.10221488340598575, 'batch_size': 16}\n",
      "Best LoRA F1: 0.3162\n"
     ]
    }
   ],
   "source": [
    "def lora_objective(trial):\n",
    "    \"\"\"Optuna objective for LoRA fine-tuning.\"\"\"\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
    "    r = trial.suggest_categorical(\"r\", [4, 8, 16])\n",
    "    alpha = trial.suggest_categorical(\"alpha\", [16, 32])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
    "    \n",
    "    lora_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        inference_mode=False,\n",
    "        r=r,\n",
    "        lora_alpha=alpha,\n",
    "        lora_dropout=dropout,\n",
    "        target_modules=[\"c_attn\", \"c_proj\"],  # GPT-Neo specific\n",
    "    )\n",
    "    \n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(all_labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "    base_model.resize_token_embeddings(len(tokenizer))\n",
    "    base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    model = get_peft_model(base_model, lora_config)\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"tmp/gpt-neo-re-lora-{trial.number}\",\n",
    "        max_steps=100,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size * 2,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=20,\n",
    "        save_strategy=\"no\",\n",
    "        learning_rate=lr,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        logging_steps=20,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer.evaluate()[\"eval_f1\"]\n",
    "\n",
    "# Run optimization\n",
    "study_lora = optuna.create_study(direction=\"maximize\")\n",
    "study_lora.optimize(lora_objective, n_trials=8)\n",
    "\n",
    "print(f\"Best LoRA params: {study_lora.best_params}\")\n",
    "print(f\"Best LoRA F1: {study_lora.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5b685-ba64-42bf-89e7-9651134257b2",
   "metadata": {},
   "source": [
    "## 11. Hyperparameter Tuning - Partial Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc21193d-9cd8-4fe8-9807-ab53a1a4691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 11:04:11,661] A new study created in memory with name: no-name-547b4328-7aa8-4a10-a00f-a30e5bd37e27\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1715078000.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 31:13, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.929600</td>\n",
       "      <td>5.878881</td>\n",
       "      <td>0.019095</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.004950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.754300</td>\n",
       "      <td>5.809472</td>\n",
       "      <td>0.019095</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.004950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.627900</td>\n",
       "      <td>5.759177</td>\n",
       "      <td>0.017720</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>0.004950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.503600</td>\n",
       "      <td>5.730528</td>\n",
       "      <td>0.015839</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>0.004950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.566200</td>\n",
       "      <td>5.720163</td>\n",
       "      <td>0.015839</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>0.004950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 11:38:36,251] Trial 0 finished with value: 0.007058189430213867 and parameters: {'learning_rate': 1.3306068220496966e-05, 'batch_size': 16, 'freeze_pct': 0.46982394969503216}. Best is trial 0 with value: 0.007058189430213867.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1715078000.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 31:17, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.639400</td>\n",
       "      <td>5.288049</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.342100</td>\n",
       "      <td>5.139290</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>0.008251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.082400</td>\n",
       "      <td>5.033153</td>\n",
       "      <td>0.258659</td>\n",
       "      <td>0.016502</td>\n",
       "      <td>0.021779</td>\n",
       "      <td>0.016502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.743200</td>\n",
       "      <td>4.973281</td>\n",
       "      <td>0.216841</td>\n",
       "      <td>0.018152</td>\n",
       "      <td>0.024685</td>\n",
       "      <td>0.018152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.822500</td>\n",
       "      <td>4.951593</td>\n",
       "      <td>0.223593</td>\n",
       "      <td>0.021452</td>\n",
       "      <td>0.028844</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 12:12:58,614] Trial 1 finished with value: 0.02884399025939701 and parameters: {'learning_rate': 2.937090680094251e-05, 'batch_size': 16, 'freeze_pct': 0.29258562843873015}. Best is trial 1 with value: 0.02884399025939701.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1715078000.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 22:02, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.862300</td>\n",
       "      <td>5.423842</td>\n",
       "      <td>0.008931</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.563000</td>\n",
       "      <td>5.374379</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.614100</td>\n",
       "      <td>5.340120</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.598100</td>\n",
       "      <td>5.318691</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.445100</td>\n",
       "      <td>5.311435</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 12:37:53,138] Trial 2 finished with value: 0.007384949021217912 and parameters: {'learning_rate': 1.1799202412962498e-05, 'batch_size': 8, 'freeze_pct': 0.6950252097896465}. Best is trial 1 with value: 0.02884399025939701.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1715078000.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 16:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.901000</td>\n",
       "      <td>5.504092</td>\n",
       "      <td>0.409076</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.520600</td>\n",
       "      <td>5.470062</td>\n",
       "      <td>0.408685</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.358100</td>\n",
       "      <td>5.447033</td>\n",
       "      <td>0.408685</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.767700</td>\n",
       "      <td>5.431368</td>\n",
       "      <td>0.408685</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.277700</td>\n",
       "      <td>5.426683</td>\n",
       "      <td>0.408685</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 02:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 12:56:27,637] Trial 3 finished with value: 0.019889540208736307 and parameters: {'learning_rate': 1.0156526334275387e-05, 'batch_size': 4, 'freeze_pct': 0.2786834369142897}. Best is trial 1 with value: 0.02884399025939701.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1715078000.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 16:02, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.836700</td>\n",
       "      <td>5.433455</td>\n",
       "      <td>0.408873</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019949</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.388400</td>\n",
       "      <td>5.354009</td>\n",
       "      <td>0.410183</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.021527</td>\n",
       "      <td>0.014851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.190400</td>\n",
       "      <td>5.300453</td>\n",
       "      <td>0.343795</td>\n",
       "      <td>0.016502</td>\n",
       "      <td>0.021962</td>\n",
       "      <td>0.016502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.463700</td>\n",
       "      <td>5.264086</td>\n",
       "      <td>0.343795</td>\n",
       "      <td>0.016502</td>\n",
       "      <td>0.021962</td>\n",
       "      <td>0.016502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.986800</td>\n",
       "      <td>5.253237</td>\n",
       "      <td>0.341808</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.020156</td>\n",
       "      <td>0.014851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 02:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 13:14:59,159] Trial 4 finished with value: 0.020155780365126833 and parameters: {'learning_rate': 2.4044666584305984e-05, 'batch_size': 4, 'freeze_pct': 0.30776487110075024}. Best is trial 1 with value: 0.02884399025939701.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1715078000.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 21:59, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.726500</td>\n",
       "      <td>5.482475</td>\n",
       "      <td>0.408873</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019949</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.572400</td>\n",
       "      <td>5.430804</td>\n",
       "      <td>0.408685</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.364600</td>\n",
       "      <td>5.394678</td>\n",
       "      <td>0.408685</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.254400</td>\n",
       "      <td>5.371811</td>\n",
       "      <td>0.408685</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.321200</td>\n",
       "      <td>5.364176</td>\n",
       "      <td>0.408685</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 02:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 13:39:50,819] Trial 5 finished with value: 0.019889540208736307 and parameters: {'learning_rate': 1.2110098251616303e-05, 'batch_size': 8, 'freeze_pct': 0.5211851568310703}. Best is trial 1 with value: 0.02884399025939701.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1715078000.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 31:36, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.608200</td>\n",
       "      <td>5.377806</td>\n",
       "      <td>0.408685</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.143200</td>\n",
       "      <td>5.247519</td>\n",
       "      <td>0.342275</td>\n",
       "      <td>0.014851</td>\n",
       "      <td>0.020292</td>\n",
       "      <td>0.014851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.046600</td>\n",
       "      <td>5.155096</td>\n",
       "      <td>0.291872</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.018135</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.061700</td>\n",
       "      <td>5.102387</td>\n",
       "      <td>0.228744</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.886000</td>\n",
       "      <td>5.083460</td>\n",
       "      <td>0.228335</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.013201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 14:14:33,622] Trial 6 finished with value: 0.017993030072237993 and parameters: {'learning_rate': 2.4863795902757856e-05, 'batch_size': 16, 'freeze_pct': 0.5861776440284465}. Best is trial 1 with value: 0.02884399025939701.\n",
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\1715078000.py:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 16:08, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.832300</td>\n",
       "      <td>5.340235</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.564900</td>\n",
       "      <td>5.241562</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.006601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.990100</td>\n",
       "      <td>5.173745</td>\n",
       "      <td>0.009688</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.008812</td>\n",
       "      <td>0.008251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.396000</td>\n",
       "      <td>5.126965</td>\n",
       "      <td>0.009307</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.008251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.104000</td>\n",
       "      <td>5.113170</td>\n",
       "      <td>0.009307</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.008251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 02:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 14:33:12,398] Trial 7 finished with value: 0.008623390622387376 and parameters: {'learning_rate': 3.160188360935759e-05, 'batch_size': 4, 'freeze_pct': 0.7260373799188917}. Best is trial 1 with value: 0.02884399025939701.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Freeze params: {'learning_rate': 2.937090680094251e-05, 'batch_size': 16, 'freeze_pct': 0.29258562843873015}\n",
      "Best Freeze F1: 0.0288\n"
     ]
    }
   ],
   "source": [
    "def freeze_objective(trial):\n",
    "    \"\"\"Optuna objective for partial freezing.\"\"\"\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
    "    freeze_pct = trial.suggest_float(\"freeze_pct\", 0.25, 0.75)\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(all_labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    # Freeze lower layers\n",
    "    total_layers = len([n for n, _ in model.named_parameters() if n.startswith(\"transformer.h.\")])\n",
    "    layers_to_freeze = int(total_layers * freeze_pct)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if name.startswith(\"transformer.h.\"):\n",
    "            layer_num = int(name.split(\".\")[2])\n",
    "            if layer_num < layers_to_freeze:\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"tmp/gpt-neo-re-freeze-{trial.number}\",\n",
    "        max_steps=100,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size * 2,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=20,\n",
    "        save_strategy=\"no\",\n",
    "        learning_rate=lr,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        logging_steps=20,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    return trainer.evaluate()[\"eval_f1\"]\n",
    "\n",
    "# Run optimization\n",
    "study_freeze = optuna.create_study(direction=\"maximize\")\n",
    "study_freeze.optimize(freeze_objective, n_trials=8)\n",
    "\n",
    "print(f\"Best Freeze params: {study_freeze.best_params}\")\n",
    "print(f\"Best Freeze F1: {study_freeze.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58109943-b625-4996-ace1-29d6c70d9474",
   "metadata": {},
   "source": [
    "## 12. Final Training with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b899c390-108c-40fa-afbb-725ebec8bdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FULL FINE-TUNING WITH BEST PARAMETERS\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\3442874944.py:36: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  ft_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 1:11:16, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.552944</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.488449</td>\n",
       "      <td>0.330726</td>\n",
       "      <td>0.488449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.212564</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.458746</td>\n",
       "      <td>0.323632</td>\n",
       "      <td>0.458746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.054219</td>\n",
       "      <td>0.262225</td>\n",
       "      <td>0.473597</td>\n",
       "      <td>0.336129</td>\n",
       "      <td>0.473597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.958941</td>\n",
       "      <td>0.255776</td>\n",
       "      <td>0.473597</td>\n",
       "      <td>0.329424</td>\n",
       "      <td>0.473597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.978882</td>\n",
       "      <td>0.265758</td>\n",
       "      <td>0.457096</td>\n",
       "      <td>0.335303</td>\n",
       "      <td>0.457096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.001741</td>\n",
       "      <td>0.263627</td>\n",
       "      <td>0.462046</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>0.462046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.998628</td>\n",
       "      <td>0.263115</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.332699</td>\n",
       "      <td>0.455446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.982560</td>\n",
       "      <td>0.266552</td>\n",
       "      <td>0.458746</td>\n",
       "      <td>0.336088</td>\n",
       "      <td>0.458746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.988353</td>\n",
       "      <td>0.265989</td>\n",
       "      <td>0.457096</td>\n",
       "      <td>0.335423</td>\n",
       "      <td>0.457096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.989139</td>\n",
       "      <td>0.265989</td>\n",
       "      <td>0.457096</td>\n",
       "      <td>0.335423</td>\n",
       "      <td>0.457096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full FT F1: 0.3354\n",
      "\n",
      "==================================================\n",
      "LoRA WITH BEST PARAMETERS\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\3442874944.py:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  lora_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 427,008 || all params: 125,684,736 || trainable%: 0.3397\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 1:08:46, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.375581</td>\n",
       "      <td>0.253684</td>\n",
       "      <td>0.397690</td>\n",
       "      <td>0.309769</td>\n",
       "      <td>0.397690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.395220</td>\n",
       "      <td>0.261351</td>\n",
       "      <td>0.343234</td>\n",
       "      <td>0.296504</td>\n",
       "      <td>0.343234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.329165</td>\n",
       "      <td>0.252801</td>\n",
       "      <td>0.293729</td>\n",
       "      <td>0.270923</td>\n",
       "      <td>0.293729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.225821</td>\n",
       "      <td>0.255609</td>\n",
       "      <td>0.387789</td>\n",
       "      <td>0.308112</td>\n",
       "      <td>0.387789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.352839</td>\n",
       "      <td>0.249933</td>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.275019</td>\n",
       "      <td>0.306931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.313124</td>\n",
       "      <td>0.262641</td>\n",
       "      <td>0.369637</td>\n",
       "      <td>0.307077</td>\n",
       "      <td>0.369637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.309341</td>\n",
       "      <td>0.253253</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.287715</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.262595</td>\n",
       "      <td>0.252883</td>\n",
       "      <td>0.349835</td>\n",
       "      <td>0.293519</td>\n",
       "      <td>0.349835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.300770</td>\n",
       "      <td>0.244165</td>\n",
       "      <td>0.303630</td>\n",
       "      <td>0.270389</td>\n",
       "      <td>0.303630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.282853</td>\n",
       "      <td>0.254605</td>\n",
       "      <td>0.343234</td>\n",
       "      <td>0.292278</td>\n",
       "      <td>0.343234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA F1: 0.2923\n",
      "\n",
      "==================================================\n",
      "PARTIAL FREEZING WITH BEST PARAMETERS\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoForSequenceClassification were not initialized from the model checkpoint at EleutherAI/gpt-neo-125M and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 40,230,912 / 125,257,728 (32.12%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_31248\\3442874944.py:147: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  freeze_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 1:05:14, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.784083</td>\n",
       "      <td>0.020813</td>\n",
       "      <td>0.021452</td>\n",
       "      <td>0.019587</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.607088</td>\n",
       "      <td>0.017473</td>\n",
       "      <td>0.023102</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>0.023102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.448545</td>\n",
       "      <td>0.159627</td>\n",
       "      <td>0.026403</td>\n",
       "      <td>0.025260</td>\n",
       "      <td>0.026403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.319882</td>\n",
       "      <td>0.157054</td>\n",
       "      <td>0.026403</td>\n",
       "      <td>0.023538</td>\n",
       "      <td>0.026403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.209702</td>\n",
       "      <td>0.181282</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.027534</td>\n",
       "      <td>0.029703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.124040</td>\n",
       "      <td>0.306954</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.047246</td>\n",
       "      <td>0.039604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.058703</td>\n",
       "      <td>0.292266</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.048029</td>\n",
       "      <td>0.039604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.013437</td>\n",
       "      <td>0.301094</td>\n",
       "      <td>0.042904</td>\n",
       "      <td>0.054189</td>\n",
       "      <td>0.042904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.987550</td>\n",
       "      <td>0.310834</td>\n",
       "      <td>0.044554</td>\n",
       "      <td>0.057152</td>\n",
       "      <td>0.044554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.978530</td>\n",
       "      <td>0.310413</td>\n",
       "      <td>0.044554</td>\n",
       "      <td>0.057077</td>\n",
       "      <td>0.044554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 02:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial Freeze F1: 0.0571\n"
     ]
    }
   ],
   "source": [
    "# Store results\n",
    "results_summary = {\n",
    "    \"baseline\": baseline_metrics,\n",
    "    \"full_ft\": None,\n",
    "    \"lora\": None,\n",
    "    \"partial_freeze\": None\n",
    "}\n",
    "\n",
    "# Full Fine-Tuning with best params\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FULL FINE-TUNING WITH BEST PARAMETERS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_ft_params = study_ft.best_params\n",
    "ft_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(all_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "ft_model.resize_token_embeddings(len(tokenizer))\n",
    "ft_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "ft_args = TrainingArguments(\n",
    "    output_dir=\"outputs/gpt-neo-re-ft-final\",\n",
    "    max_steps=200,\n",
    "    per_device_train_batch_size=best_ft_params[\"batch_size\"],\n",
    "    per_device_eval_batch_size=best_ft_params[\"batch_size\"] * 2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=best_ft_params[\"learning_rate\"],\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "ft_trainer = Trainer(\n",
    "    model=ft_model,\n",
    "    args=ft_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "ft_trainer.train()\n",
    "ft_metrics = ft_trainer.evaluate()\n",
    "results_summary[\"full_ft\"] = ft_metrics\n",
    "print(f\"Full FT F1: {ft_metrics['eval_f1']:.4f}\")\n",
    "\n",
    "# LoRA with best params\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LoRA WITH BEST PARAMETERS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_lora_params = study_lora.best_params\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=best_lora_params[\"r\"],\n",
    "    lora_alpha=best_lora_params[\"alpha\"],\n",
    "    lora_dropout=best_lora_params[\"dropout\"],\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    ")\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(all_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "lora_model = get_peft_model(base_model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "\n",
    "lora_args = TrainingArguments(\n",
    "    output_dir=\"outputs/gpt-neo-re-lora-final\",\n",
    "    max_steps=200,\n",
    "    per_device_train_batch_size=best_lora_params[\"batch_size\"],\n",
    "    per_device_eval_batch_size=best_lora_params[\"batch_size\"] * 2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=best_lora_params[\"learning_rate\"],\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "lora_trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=lora_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "lora_trainer.train()\n",
    "lora_metrics = lora_trainer.evaluate()\n",
    "results_summary[\"lora\"] = lora_metrics\n",
    "print(f\"LoRA F1: {lora_metrics['eval_f1']:.4f}\")\n",
    "\n",
    "# Partial Freezing with best params\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PARTIAL FREEZING WITH BEST PARAMETERS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_freeze_params = study_freeze.best_params\n",
    "freeze_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(all_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "freeze_model.resize_token_embeddings(len(tokenizer))\n",
    "freeze_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Apply freezing\n",
    "total_layers = len([n for n, _ in freeze_model.named_parameters() if n.startswith(\"transformer.h.\")])\n",
    "layers_to_freeze = int(total_layers * best_freeze_params[\"freeze_pct\"])\n",
    "\n",
    "for name, param in freeze_model.named_parameters():\n",
    "    if name.startswith(\"transformer.h.\"):\n",
    "        layer_num = int(name.split(\".\")[2])\n",
    "        if layer_num < layers_to_freeze:\n",
    "            param.requires_grad = False\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_params = sum(p.numel() for p in freeze_model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in freeze_model.parameters())\n",
    "print(f\"Trainable parameters: {trainable_params:,} / {total_params:,} ({trainable_params/total_params*100:.2f}%)\")\n",
    "\n",
    "freeze_args = TrainingArguments(\n",
    "    output_dir=\"outputs/gpt-neo-re-freeze-final\",\n",
    "    max_steps=200,\n",
    "    per_device_train_batch_size=best_freeze_params[\"batch_size\"],\n",
    "    per_device_eval_batch_size=best_freeze_params[\"batch_size\"] * 2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=best_freeze_params[\"learning_rate\"],\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "freeze_trainer = Trainer(\n",
    "    model=freeze_model,\n",
    "    args=freeze_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "freeze_trainer.train()\n",
    "freeze_metrics = freeze_trainer.evaluate()\n",
    "results_summary[\"partial_freeze\"] = freeze_metrics\n",
    "print(f\"Partial Freeze F1: {freeze_metrics['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b71cad9-3f48-4256-814a-9f168d371132",
   "metadata": {},
   "source": [
    "## 13. Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1256832-7755-42aa-9a56-4dcea8fbec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GPT-NEO RELATION EXTRACTION RESULTS\n",
      "==================================================\n",
      "        Method    F1  Precision  Recall  Accuracy\n",
      "      Baseline 29.94      26.64   35.48     35.48\n",
      "       Full Ft 33.54      26.60   45.71     45.71\n",
      "          Lora 29.23      25.46   34.32     34.32\n",
      "Partial Freeze  5.71      31.04    4.46      4.46\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Best performing method: Full Ft\n",
      "   F1 Score: 33.54%\n",
      "   Accuracy: 45.71%\n"
     ]
    }
   ],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "for method, metrics in results_summary.items():\n",
    "    comparison_data.append({\n",
    "        \"Method\": method.replace(\"_\", \" \").title(),\n",
    "        \"F1\": metrics[\"eval_f1\"] * 100,\n",
    "        \"Precision\": metrics[\"eval_precision\"] * 100,\n",
    "        \"Recall\": metrics[\"eval_recall\"] * 100,\n",
    "        \"Accuracy\": metrics[\"eval_accuracy\"] * 100,\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.round(2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GPT-NEO RELATION EXTRACTION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# F1 Score comparison\n",
    "methods = comparison_df[\"Method\"].tolist()\n",
    "f1_scores = comparison_df[\"F1\"].tolist()\n",
    "\n",
    "ax1.bar(methods, f1_scores, color=['skyblue', 'lightgreen', 'coral', 'gold'])\n",
    "ax1.set_ylabel('F1 Score (%)')\n",
    "ax1.set_title('GPT-Neo RE - F1 Score Comparison')\n",
    "ax1.set_ylim(0, 100)\n",
    "\n",
    "for i, v in enumerate(f1_scores):\n",
    "    ax1.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "# Accuracy comparison\n",
    "accuracies = comparison_df[\"Accuracy\"].tolist()\n",
    "ax2.bar(methods, accuracies, color=['skyblue', 'lightgreen', 'coral', 'gold'])\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('GPT-Neo RE - Accuracy Comparison')\n",
    "ax2.set_ylim(0, 100)\n",
    "\n",
    "for i, v in enumerate(accuracies):\n",
    "    ax2.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/gpt_neo_re_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Best performing method\n",
    "best_method_idx = comparison_df[\"F1\"].idxmax()\n",
    "best_method = comparison_df.iloc[best_method_idx]\n",
    "print(f\"\\n🏆 Best performing method: {best_method['Method']}\")\n",
    "print(f\"   F1 Score: {best_method['F1']:.2f}%\")\n",
    "print(f\"   Accuracy: {best_method['Accuracy']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b4fb2-bb6c-45f8-bd8a-cee8c6bc8e7e",
   "metadata": {},
   "source": [
    "## 14. Hyperparameter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd78e618-ed4e-4072-838d-97169ef447ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "HYPERPARAMETER ANALYSIS\n",
      "==================================================\n",
      "\n",
      "📊 Full Fine-Tuning Best Parameters:\n",
      "  learning_rate: 2.903968752043959e-05\n",
      "  batch_size: 16\n",
      "\n",
      "📊 LoRA Best Parameters:\n",
      "  learning_rate: 0.00046162295786666236\n",
      "  r: 8\n",
      "  alpha: 16\n",
      "  dropout: 0.10221488340598575\n",
      "  batch_size: 16\n",
      "\n",
      "📊 Partial Freeze Best Parameters:\n",
      "  learning_rate: 2.937090680094251e-05\n",
      "  batch_size: 16\n",
      "  freeze_pct: 0.29258562843873015\n",
      "\n",
      "✅ Results saved to outputs/gpt_neo_re_results.csv\n",
      "💾 Best model saved to outputs/gpt-neo-re-best-model/\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"HYPERPARAMETER ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n📊 Full Fine-Tuning Best Parameters:\")\n",
    "for param, value in study_ft.best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\n📊 LoRA Best Parameters:\")\n",
    "for param, value in study_lora.best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\n📊 Partial Freeze Best Parameters:\")\n",
    "for param, value in study_freeze.best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "# Save results\n",
    "comparison_df.to_csv(\"outputs/gpt_neo_re_results.csv\", index=False)\n",
    "print(\"\\n✅ Results saved to outputs/gpt_neo_re_results.csv\")\n",
    "\n",
    "# Save best model\n",
    "best_trainer = ft_trainer if best_method['Method'] == 'Full Ft' else (\n",
    "    lora_trainer if best_method['Method'] == 'Lora' else freeze_trainer\n",
    ")\n",
    "best_trainer.save_model(\"outputs/gpt-neo-re-best-model\")\n",
    "tokenizer.save_pretrained(\"outputs/gpt-neo-re-best-model\")\n",
    "print(\"💾 Best model saved to outputs/gpt-neo-re-best-model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e8c9a-1f37-43e8-8696-5ef58e4e564f",
   "metadata": {},
   "source": [
    "## 15. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fce0dc29-c608-4623-9bc5-06834793bcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Summary report saved to outputs/gpt_neo_re_summary.json\n"
     ]
    }
   ],
   "source": [
    "# Create summary report\n",
    "summary = {\n",
    "    \"task\": \"Relation Extraction\",\n",
    "    \"model\": \"GPT-Neo 125M\",\n",
    "    \"dataset\": \"DocIE\",\n",
    "    \"best_method\": best_method['Method'],\n",
    "    \"best_f1\": float(best_method['F1']),\n",
    "    \"best_accuracy\": float(best_method['Accuracy']),\n",
    "    \"training_examples\": len(train_dataset),\n",
    "    \"dev_examples\": len(dev_dataset),\n",
    "    \"num_classes\": len(all_labels),\n",
    "    \"hyperparameter_trials\": 8,\n",
    "    \"fine_tuning_methods\": [\"Full Fine-Tuning\", \"LoRA\", \"Partial Freezing\"]\n",
    "}\n",
    "\n",
    "with open(\"outputs/gpt_neo_re_summary.json\", \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\n📊 Summary report saved to outputs/gpt_neo_re_summary.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
