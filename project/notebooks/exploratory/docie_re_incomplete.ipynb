{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1370f9fc-6fde-4858-8ff3-af6fc59b35f4",
   "metadata": {},
   "source": [
    "# 1. Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d211c2c-ce7d-4c3a-b670-39955b26ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import BertForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475415a1-75e6-4f11-a80b-0b24c3e0b959",
   "metadata": {},
   "source": [
    "# 2. Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc3027cf-aec6-4795-a764-2cbd01df1711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test samples loaded: 248\n",
      "                 domain                                           document  \\\n",
      "0  Academic_disciplines  The Anthropocene Working Group (AWG) is an int...   \n",
      "1  Academic_disciplines  Applied history is the effort to apply insight...   \n",
      "2  Academic_disciplines  Bolognese bell ringing is a tradition of ringi...   \n",
      "3  Academic_disciplines  The Cylinder Audio Archive is a free digital c...   \n",
      "4  Academic_disciplines  Drug education is the planned provision of inf...   \n",
      "\n",
      "                                        RE_label_set  \\\n",
      "0  [facet of, field of work, family name, applies...   \n",
      "1  [facet of, field of work, family name, applies...   \n",
      "2  [facet of, field of work, family name, applies...   \n",
      "3  [facet of, field of work, family name, applies...   \n",
      "4  [facet of, field of work, family name, applies...   \n",
      "\n",
      "                                       NER_label_set                      id  \n",
      "0  [essentially contested concept, art term, prod...  Academic_disciplines_0  \n",
      "1  [essentially contested concept, art term, prod...  Academic_disciplines_1  \n",
      "2  [essentially contested concept, art term, prod...  Academic_disciplines_2  \n",
      "3  [essentially contested concept, art term, prod...  Academic_disciplines_3  \n",
      "4  [essentially contested concept, art term, prod...  Academic_disciplines_4  \n"
     ]
    }
   ],
   "source": [
    "# Pfad zu deinem Test-Ordner\n",
    "test_folder = r\"C:\\Users\\nmilo\\OneDrive\\Desktop\\Master\\Semester2\\NLP\\project\\dataset\\test\"\n",
    "\n",
    "# Leerer DataFrame zum Sammeln aller Testdaten\n",
    "all_test_data = []\n",
    "\n",
    "# Alle Unterordner durchgehen\n",
    "for subdir, dirs, files in os.walk(test_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            filepath = os.path.join(subdir, file)\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                # Falls die Daten eine Liste sind:\n",
    "                if isinstance(data, list):\n",
    "                    all_test_data.extend(data)\n",
    "                else:\n",
    "                    all_test_data.append(data)\n",
    "\n",
    "# Gesamte Test-Daten in einem DataFrame speichern\n",
    "test_df = pd.DataFrame(all_test_data)\n",
    "\n",
    "# Ergebnis kontrollieren\n",
    "print(f\"Total test samples loaded: {len(test_df)}\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b517334-a801-4f63-9926-a445b6398a43",
   "metadata": {},
   "source": [
    "# 3. Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b36afd3a-fa3d-40b6-8a6d-68acf72799f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Text: The Anthropocene Working Group (AWG) is an interdisciplinary research group dedicated to the study of the Anthropocene as a geological time unit. It was established in 2009 as part of the Subcommission on Quaternary Stratigraphy (SQS), a constituent body of the International Commission on Stratigraphy (ICS). As of 2021, the research group features 37 members, with the physical geographer Simon Turner as Secretary and the geologist Colin Neil Waters as chair of the group. The late Nobel Prize-win\n"
     ]
    }
   ],
   "source": [
    "test_df.head()\n",
    "\n",
    "# Get texts from the correct column\n",
    "texts = test_df[\"document\"].tolist()\n",
    "\n",
    "# Check an example\n",
    "print(\"Example Text:\", texts[0][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1571050-0ecd-48f5-b9d0-0fba710210d2",
   "metadata": {},
   "source": [
    "# 4. Baseline: Evaluate Raw BERT (no training yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4ad93d-c331-411b-bf80-41ee5b2ed2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline NER predictions example: [{'entity_group': 'LABEL_0', 'score': 0.6277717, 'word': 'The Anthropocene Working Group', 'start': 0, 'end': 30}, {'entity_group': 'LABEL_1', 'score': 0.5698104, 'word': '(', 'start': 31, 'end': 32}, {'entity_group': 'LABEL_0', 'score': 0.6045339, 'word': 'AWG ) is an interdisciplinary research group dedicated', 'start': 32, 'end': 85}, {'entity_group': 'LABEL_1', 'score': 0.53525066, 'word': 'to the', 'start': 86, 'end': 92}, {'entity_group': 'LABEL_0', 'score': 0.632875, 'word': 'study of the Anthropocene as a geological time unit', 'start': 93, 'end': 144}, {'entity_group': 'LABEL_1', 'score': 0.516107, 'word': '.', 'start': 144, 'end': 145}, {'entity_group': 'LABEL_0', 'score': 0.63311535, 'word': 'It was established in 2009', 'start': 146, 'end': 172}, {'entity_group': 'LABEL_1', 'score': 0.54079366, 'word': 'as part', 'start': 173, 'end': 180}, {'entity_group': 'LABEL_0', 'score': 0.54305744, 'word': 'of the', 'start': 181, 'end': 187}, {'entity_group': 'LABEL_1', 'score': 0.54794765, 'word': 'Sub', 'start': 188, 'end': 191}, {'entity_group': 'LABEL_0', 'score': 0.6272133, 'word': '##commission on Quaternary Stratigraphy', 'start': 191, 'end': 228}, {'entity_group': 'LABEL_1', 'score': 0.606597, 'word': '(', 'start': 229, 'end': 230}, {'entity_group': 'LABEL_0', 'score': 0.55660856, 'word': 'SQS )', 'start': 230, 'end': 234}, {'entity_group': 'LABEL_1', 'score': 0.5620341, 'word': ', a constituent', 'start': 234, 'end': 249}, {'entity_group': 'LABEL_0', 'score': 0.5891823, 'word': 'body', 'start': 250, 'end': 254}, {'entity_group': 'LABEL_1', 'score': 0.52371955, 'word': 'of the International', 'start': 255, 'end': 275}, {'entity_group': 'LABEL_0', 'score': 0.6089869, 'word': 'Commission on Stratigraphy', 'start': 276, 'end': 302}, {'entity_group': 'LABEL_1', 'score': 0.55500853, 'word': '( I', 'start': 303, 'end': 305}, {'entity_group': 'LABEL_0', 'score': 0.64974254, 'word': '##CS', 'start': 305, 'end': 307}, {'entity_group': 'LABEL_1', 'score': 0.53019744, 'word': '). As', 'start': 307, 'end': 312}, {'entity_group': 'LABEL_0', 'score': 0.60324484, 'word': 'of 2021, the', 'start': 313, 'end': 325}, {'entity_group': 'LABEL_1', 'score': 0.50341344, 'word': 'research', 'start': 326, 'end': 334}, {'entity_group': 'LABEL_0', 'score': 0.61991066, 'word': 'group features 37 members', 'start': 335, 'end': 360}, {'entity_group': 'LABEL_1', 'score': 0.51089424, 'word': ',', 'start': 360, 'end': 361}, {'entity_group': 'LABEL_0', 'score': 0.6051563, 'word': 'with the physical geographer Simon Turner as Secretary and the geologist Colin Neil Waters as chair of the group', 'start': 362, 'end': 474}, {'entity_group': 'LABEL_1', 'score': 0.51524234, 'word': '.', 'start': 474, 'end': 475}, {'entity_group': 'LABEL_0', 'score': 0.5824786, 'word': 'The late Nobel Prize - winning Paul', 'start': 476, 'end': 509}, {'entity_group': 'LABEL_1', 'score': 0.58607453, 'word': 'Cru', 'start': 510, 'end': 513}, {'entity_group': 'LABEL_0', 'score': 0.5870731, 'word': '##tzen,', 'start': 513, 'end': 518}, {'entity_group': 'LABEL_1', 'score': 0.5689869, 'word': 'who', 'start': 519, 'end': 522}, {'entity_group': 'LABEL_0', 'score': 0.5436202, 'word': 'popularized', 'start': 523, 'end': 534}, {'entity_group': 'LABEL_1', 'score': 0.5251639, 'word': 'the', 'start': 535, 'end': 538}, {'entity_group': 'LABEL_0', 'score': 0.6593069, 'word': \"word ' Anthropocene ' in 2000\", 'start': 539, 'end': 566}, {'entity_group': 'LABEL_1', 'score': 0.5915873, 'word': ',', 'start': 566, 'end': 567}, {'entity_group': 'LABEL_0', 'score': 0.6229128, 'word': 'had also been a member of the group until he died on January 28,', 'start': 568, 'end': 632}, {'entity_group': 'LABEL_1', 'score': 0.5098922, 'word': '202', 'start': 633, 'end': 636}, {'entity_group': 'LABEL_0', 'score': 0.7395197, 'word': '##1', 'start': 636, 'end': 637}, {'entity_group': 'LABEL_1', 'score': 0.51486313, 'word': '.', 'start': 637, 'end': 638}, {'entity_group': 'LABEL_0', 'score': 0.545345, 'word': 'The', 'start': 639, 'end': 642}, {'entity_group': 'LABEL_1', 'score': 0.5169643, 'word': 'main goal', 'start': 643, 'end': 652}, {'entity_group': 'LABEL_0', 'score': 0.647692, 'word': 'of the AWG is providing scientific evidence robust enough for the Anthropocene to be formally ratified by', 'start': 653, 'end': 758}, {'entity_group': 'LABEL_1', 'score': 0.5340947, 'word': 'the International', 'start': 759, 'end': 776}, {'entity_group': 'LABEL_0', 'score': 0.53238523, 'word': 'Union', 'start': 777, 'end': 782}, {'entity_group': 'LABEL_1', 'score': 0.58065665, 'word': 'of', 'start': 783, 'end': 785}, {'entity_group': 'LABEL_0', 'score': 0.5385272, 'word': 'Geological Sciences', 'start': 786, 'end': 805}, {'entity_group': 'LABEL_1', 'score': 0.5266622, 'word': '(', 'start': 806, 'end': 807}, {'entity_group': 'LABEL_0', 'score': 0.50133395, 'word': 'I', 'start': 807, 'end': 808}, {'entity_group': 'LABEL_1', 'score': 0.55984455, 'word': '##UGS )', 'start': 808, 'end': 812}, {'entity_group': 'LABEL_0', 'score': 0.58392733, 'word': 'as an epoch within the', 'start': 813, 'end': 835}, {'entity_group': 'LABEL_1', 'score': 0.5167083, 'word': 'G', 'start': 836, 'end': 837}, {'entity_group': 'LABEL_0', 'score': 0.65975785, 'word': '##eologic time scale', 'start': 837, 'end': 855}, {'entity_group': 'LABEL_1', 'score': 0.51501197, 'word': '.', 'start': 855, 'end': 856}, {'entity_group': 'LABEL_0', 'score': 0.6337758, 'word': 'Prior to the establishment of the Anthropocene Working Group in 2009,', 'start': 857, 'end': 926}, {'entity_group': 'LABEL_1', 'score': 0.50813913, 'word': 'no', 'start': 927, 'end': 929}, {'entity_group': 'LABEL_0', 'score': 0.6042281, 'word': 'research program dedicated', 'start': 930, 'end': 956}, {'entity_group': 'LABEL_1', 'score': 0.5678594, 'word': 'to', 'start': 957, 'end': 959}, {'entity_group': 'LABEL_0', 'score': 0.6156201, 'word': 'the formalization of the Anthropocene in the geologic time scale existed', 'start': 960, 'end': 1032}, {'entity_group': 'LABEL_1', 'score': 0.515146, 'word': '.', 'start': 1032, 'end': 1033}, {'entity_group': 'LABEL_0', 'score': 0.5525024, 'word': 'The idea of naming the current', 'start': 1034, 'end': 1064}, {'entity_group': 'LABEL_1', 'score': 0.50683755, 'word': 'e', 'start': 1065, 'end': 1066}, {'entity_group': 'LABEL_0', 'score': 0.58475953, 'word': '##po', 'start': 1066, 'end': 1068}, {'entity_group': 'LABEL_1', 'score': 0.5209128, 'word': '##ch', 'start': 1068, 'end': 1070}, {'entity_group': 'LABEL_0', 'score': 0.60383797, 'word': \"' Anthropocene ' rather than using its formal time unit\", 'start': 1071, 'end': 1124}, {'entity_group': 'LABEL_1', 'score': 0.5867694, 'word': ',', 'start': 1124, 'end': 1125}, {'entity_group': 'LABEL_0', 'score': 0.60011226, 'word': 'the Holocene, became popular after Paul', 'start': 1126, 'end': 1165}, {'entity_group': 'LABEL_1', 'score': 0.59163606, 'word': 'Cru', 'start': 1166, 'end': 1169}, {'entity_group': 'LABEL_0', 'score': 0.6388868, 'word': '##tzen and Eugene Stoermer published in May 2000 an article on the IGBP Global Change Newsletter called \" The \\' Anthropocene \\'', 'start': 1169, 'end': 1290}, {'entity_group': 'LABEL_1', 'score': 0.5068328, 'word': '.', 'start': 1290, 'end': 1291}, {'entity_group': 'LABEL_0', 'score': 0.6532966, 'word': '\" Later in 2002,', 'start': 1291, 'end': 1307}, {'entity_group': 'LABEL_1', 'score': 0.5552755, 'word': 'C', 'start': 1308, 'end': 1309}, {'entity_group': 'LABEL_0', 'score': 0.62866545, 'word': '##rutzen published a commentary on Nature titled \" Geology of Mankind \" where he further stressed the idea \" to assign the term ‘ Anthropocene ’ to the present, in many ways human - dominated, geological epoch, supplementing the Holocene, \" with starting date in the late 18th century ( at the onset of the Industrial Revolution )', 'start': 1309, 'end': 1627}, {'entity_group': 'LABEL_1', 'score': 0.514525, 'word': '.', 'start': 1627, 'end': 1628}, {'entity_group': 'LABEL_0', 'score': 0.68986845, 'word': \"Soon after Paul Crutzen published his influential articles, a debate over the beginning of the Anthropocene took place between supporters of the Early Anthropocene Hypothesis, a thesis originally promoted in 2003 by the palaeoclimatologist William Ruddiman dating the beginning of the Anthropocene as far back as the Neolithic Revolution, and supporters of more recent starting dates, from European Colonization of the Americas, to the late 18th century, to the post - WWII Great Acceleration. The discussion over the beginning of the Anthropocene was crucial for the ' stratigraphic turn ' that\", 'start': 1629, 'end': 2220}]\n"
     ]
    }
   ],
   "source": [
    "# Baseline (Raw BERT) for Named Entity Recognition (as a proxy baseline)\n",
    "ner_pipeline = pipeline(\"ner\", model=\"bert-base-cased\", aggregation_strategy=\"simple\")\n",
    "\n",
    "# Perform baseline predictions on a single example\n",
    "baseline_preds = ner_pipeline(texts[0])\n",
    "\n",
    "print(\"Baseline NER predictions example:\", baseline_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8bfce0-2cc5-47a1-8a11-f440796aa094",
   "metadata": {},
   "source": [
    "# 5. Prepare Data for Training (Fine-Tuning BERT for Relation Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3de084d1-5758-475b-8bdb-14e21823c8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['domain', 'document', 'RE_label_set', 'NER_label_set', 'id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18470cbf-f89c-4576-9805-1c4461fa6a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b391412c5ea4e068b312b9a6d48b1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data preparation finished successfully.\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['document', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 198\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['document', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 50\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract the single relation label from each list\n",
    "test_df[\"single_label\"] = test_df[\"RE_label_set\"].apply(lambda x: x[0])\n",
    "\n",
    "# Step 2: Create label mapping dictionaries\n",
    "label_list = test_df[\"single_label\"].unique().tolist()\n",
    "label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "# Step 3: Map string labels to numeric IDs\n",
    "test_df[\"numeric_label\"] = test_df[\"single_label\"].map(label2id)\n",
    "\n",
    "# Step 4: Create Huggingface-compatible dataset\n",
    "dataset = Dataset.from_pandas(\n",
    "    test_df[['document', 'numeric_label']].rename(columns={'numeric_label': 'label'})\n",
    ")\n",
    "\n",
    "# Step 5: Load tokenizer and tokenize the documents\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"document\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Step 6: Train/test split\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "print(\"✅ Data preparation finished successfully.\")\n",
    "print(split_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d96fd5d-6448-4b0b-93d1-6985b4e19cb1",
   "metadata": {},
   "source": [
    "# 6. Train  Relation Extraction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22a4650f-dd36-4834-b359-9e2a197771f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0fb8dbe9dd45c3821967fb0a4c681c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMultiLabelClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultiLabelClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForMultiLabelClassification.forward` and have been ignored: document, token_type_ids. If document, token_type_ids are not expected by `BertForMultiLabelClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 198\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 150\n",
      "  Number of trainable parameters = 108491756\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 08:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.545100</td>\n",
       "      <td>0.523465</td>\n",
       "      <td>0.088656</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.464800</td>\n",
       "      <td>0.464730</td>\n",
       "      <td>0.096698</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.448800</td>\n",
       "      <td>0.448780</td>\n",
       "      <td>0.092425</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultiLabelClassification.forward` and have been ignored: document, token_type_ids. If document, token_type_ids are not expected by `BertForMultiLabelClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultiLabelClassification.forward` and have been ignored: document, token_type_ids. If document, token_type_ids are not expected by `BertForMultiLabelClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultiLabelClassification.forward` and have been ignored: document, token_type_ids. If document, token_type_ids are not expected by `BertForMultiLabelClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.5170754973093669, metrics={'train_runtime': 503.7376, 'train_samples_per_second': 1.179, 'train_steps_per_second': 0.298, 'total_flos': 156616326586368.0, 'train_loss': 0.5170754973093669, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Step 1: Extract unique labels from RE_label_set\n",
    "all_labels = sorted({label for sublist in test_df[\"RE_label_set\"] for label in sublist})\n",
    "label2id = {label: idx for idx, label in enumerate(all_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "# Step 2: Convert RE_label_set to multi-hot vectors\n",
    "def encode_labels(label_list):\n",
    "    multi_hot = [0] * len(label2id)\n",
    "    for label in label_list:\n",
    "        multi_hot[label2id[label]] = 1\n",
    "    return multi_hot\n",
    "\n",
    "test_df[\"multi_hot\"] = test_df[\"RE_label_set\"].apply(encode_labels)\n",
    "\n",
    "# Step 3: HuggingFace Dataset preparation\n",
    "dataset = Dataset.from_pandas(test_df[[\"document\", \"multi_hot\"]].rename(columns={\"multi_hot\": \"labels\"}))\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokens = tokenizer(examples[\"document\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    tokens[\"labels\"] = examples[\"labels\"]\n",
    "    return tokens\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Step 4: Train/test split\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Step 5: Custom model for multi-label loss\n",
    "class BertForMultiLabelClassification(BertForSequenceClassification):\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
    "        logits = outputs.logits\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits, labels.float())\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "model = BertForMultiLabelClassification.from_pretrained(\"bert-base-cased\", num_labels=len(label2id))\n",
    "\n",
    "# Step 6: Evaluation metrics\n",
    "def compute_metrics(p):\n",
    "    preds = (torch.sigmoid(torch.tensor(p.predictions)) > 0.5).int().numpy()\n",
    "    labels = p.label_ids\n",
    "    return {\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"accuracy\": accuracy_score(labels, preds)\n",
    "    }\n",
    "\n",
    "# Step 7: Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./relation_extraction_multilabel_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc0da8c-7936-441a-b8fd-62648c7a840c",
   "metadata": {},
   "source": [
    "# 7. Evaluate your Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f41d7a4d-5e34-4cbd-a432-128ffeeb8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultiLabelClassification.forward` and have been ignored: document, token_type_ids. If document, token_type_ids are not expected by `BertForMultiLabelClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.44877997040748596, 'eval_f1': 0.09242509615373026, 'eval_accuracy': 0.0, 'eval_runtime': 10.0312, 'eval_samples_per_second': 4.984, 'eval_steps_per_second': 1.296, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7f7aab-d02f-428b-9e59-f71186132c2d",
   "metadata": {},
   "source": [
    "# 8. Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3659a249-aee0-44a9-9028-9a81187f8755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForMultiLabelClassification.forward` and have been ignored: document, token_type_ids. If document, token_type_ids are not expected by `BertForMultiLabelClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_result = trainer.evaluate()\n",
    "f1_score = eval_result[\"eval_f1\"]\n",
    "\n",
    "labels = ['Baseline Raw BERT', 'Fine-Tuned BERT']\n",
    "f1_scores = [0.50, f1_score]  # Baseline kannst du manuell setzen oder aus Logs ziehen\n",
    "\n",
    "plt.bar(labels, f1_scores, color=['gray', 'blue'])\n",
    "plt.ylabel('F1-Score')\n",
    "plt.title('Baseline vs. Fine-Tuned Model (F1-Score)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151832ac-ed53-4973-8959-59740e08f270",
   "metadata": {},
   "source": [
    "# 9. Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b91d5e-6cde-4c1d-9e17-50f47aff088c",
   "metadata": {},
   "source": [
    "## raw models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1c9d524-69a9-4b40-9504-657ab87eec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\cd5ef92a9fb2f889e972770a36d4ed042daf221e\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\cd5ef92a9fb2f889e972770a36d4ed042daf221e\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\cd5ef92a9fb2f889e972770a36d4ed042daf221e\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\cd5ef92a9fb2f889e972770a36d4ed042daf221e\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\cd5ef92a9fb2f889e972770a36d4ed042daf221e\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fd1b6050ae439dae7e77a343db8218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"applies to jurisdiction\",\n",
      "    \"1\": \"award received\",\n",
      "    \"2\": \"characters\",\n",
      "    \"3\": \"conflict\",\n",
      "    \"4\": \"connects with\",\n",
      "    \"5\": \"different from\",\n",
      "    \"6\": \"diplomatic relation\",\n",
      "    \"7\": \"facet of\",\n",
      "    \"8\": \"founded by\",\n",
      "    \"9\": \"highest judicial authority\",\n",
      "    \"10\": \"located in or next to body of water\",\n",
      "    \"11\": \"owner of\",\n",
      "    \"12\": \"place of death\",\n",
      "    \"13\": \"practiced by\",\n",
      "    \"14\": \"said to be the same as\",\n",
      "    \"15\": \"shares border with\",\n",
      "    \"16\": \"studied in\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"applies to jurisdiction\": 0,\n",
      "    \"award received\": 1,\n",
      "    \"characters\": 2,\n",
      "    \"conflict\": 3,\n",
      "    \"connects with\": 4,\n",
      "    \"different from\": 5,\n",
      "    \"diplomatic relation\": 6,\n",
      "    \"facet of\": 7,\n",
      "    \"founded by\": 8,\n",
      "    \"highest judicial authority\": 9,\n",
      "    \"located in or next to body of water\": 10,\n",
      "    \"owner of\": 11,\n",
      "    \"place of death\": 12,\n",
      "    \"practiced by\": 13,\n",
      "    \"said to be the same as\": 14,\n",
      "    \"shares border with\": 15,\n",
      "    \"studied in\": 16\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluating RAW model: distilbert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, token_type_ids. If document, token_type_ids are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"applies to jurisdiction\",\n",
      "    \"1\": \"award received\",\n",
      "    \"2\": \"characters\",\n",
      "    \"3\": \"conflict\",\n",
      "    \"4\": \"connects with\",\n",
      "    \"5\": \"different from\",\n",
      "    \"6\": \"diplomatic relation\",\n",
      "    \"7\": \"facet of\",\n",
      "    \"8\": \"founded by\",\n",
      "    \"9\": \"highest judicial authority\",\n",
      "    \"10\": \"located in or next to body of water\",\n",
      "    \"11\": \"owner of\",\n",
      "    \"12\": \"place of death\",\n",
      "    \"13\": \"practiced by\",\n",
      "    \"14\": \"said to be the same as\",\n",
      "    \"15\": \"shares border with\",\n",
      "    \"16\": \"studied in\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"applies to jurisdiction\": 0,\n",
      "    \"award received\": 1,\n",
      "    \"characters\": 2,\n",
      "    \"conflict\": 3,\n",
      "    \"connects with\": 4,\n",
      "    \"different from\": 5,\n",
      "    \"diplomatic relation\": 6,\n",
      "    \"facet of\": 7,\n",
      "    \"founded by\": 8,\n",
      "    \"highest judicial authority\": 9,\n",
      "    \"located in or next to body of water\": 10,\n",
      "    \"owner of\": 11,\n",
      "    \"place of death\": 12,\n",
      "    \"practiced by\": 13,\n",
      "    \"said to be the same as\": 14,\n",
      "    \"shares border with\": 15,\n",
      "    \"studied in\": 16\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 distilbert-base-cased RAW Results: Accuracy = 0.0600, F1 = 0.0067, Loss = 2.8923\n",
      "\n",
      "🔍 Evaluating RAW model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: document. If document are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📉 roberta-base RAW Results: Accuracy = 0.0400, F1 = 0.0064, Loss = 2.8376\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Use only the first label per sample for raw single-label classification\n",
    "test_df[\"single_label\"] = test_df[\"RE_label_set\"].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "\n",
    "# STEP 2: Label mapping\n",
    "label_list = sorted(test_df[\"single_label\"].unique())\n",
    "label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "test_df[\"label\"] = test_df[\"single_label\"].map(label2id)\n",
    "\n",
    "# STEP 3: HuggingFace Dataset creation\n",
    "dataset = Dataset.from_pandas(test_df[[\"document\", \"label\"]])\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"document\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# STEP 4: Metrics\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        \"f1\": f1_score(p.label_ids, preds, average=\"macro\"),\n",
    "        \"accuracy\": accuracy_score(p.label_ids, preds)\n",
    "    }\n",
    "\n",
    "# STEP 5: RAW model evaluation\n",
    "raw_model_names = ['distilbert-base-cased', 'roberta-base']\n",
    "raw_results = []\n",
    "\n",
    "for model_name in raw_model_names:\n",
    "    print(f\"\\n🔍 Evaluating RAW model: {model_name}\")\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label2id),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        eval_dataset=split_dataset[\"test\"],\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    eval_result = trainer.evaluate()\n",
    "    print(f\"📉 {model_name} RAW Results: Accuracy = {eval_result['eval_accuracy']:.4f}, \"\n",
    "          f\"F1 = {eval_result['eval_f1']:.4f}, Loss = {eval_result['eval_loss']:.4f}\")\n",
    "\n",
    "    raw_results.append({\n",
    "        \"model\": model_name + \" (raw)\",\n",
    "        \"accuracy\": eval_result[\"eval_accuracy\"],\n",
    "        \"f1\": eval_result[\"eval_f1\"],\n",
    "        \"loss\": eval_result[\"eval_loss\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab63ba-503b-42e8-9481-98d9f53fba85",
   "metadata": {},
   "source": [
    "## fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efef218b-26b4-4ad1-b53b-11304f08963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ebdcdac405452e9c5fda84d76d0dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Training & Evaluation: distilbert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"applies to jurisdiction\",\n",
      "    \"1\": \"award received\",\n",
      "    \"2\": \"characters\",\n",
      "    \"3\": \"conflict\",\n",
      "    \"4\": \"connects with\",\n",
      "    \"5\": \"different from\",\n",
      "    \"6\": \"diplomatic relation\",\n",
      "    \"7\": \"facet of\",\n",
      "    \"8\": \"founded by\",\n",
      "    \"9\": \"highest judicial authority\",\n",
      "    \"10\": \"located in or next to body of water\",\n",
      "    \"11\": \"owner of\",\n",
      "    \"12\": \"place of death\",\n",
      "    \"13\": \"practiced by\",\n",
      "    \"14\": \"said to be the same as\",\n",
      "    \"15\": \"shares border with\",\n",
      "    \"16\": \"studied in\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"applies to jurisdiction\": 0,\n",
      "    \"award received\": 1,\n",
      "    \"characters\": 2,\n",
      "    \"conflict\": 3,\n",
      "    \"connects with\": 4,\n",
      "    \"different from\": 5,\n",
      "    \"diplomatic relation\": 6,\n",
      "    \"facet of\": 7,\n",
      "    \"founded by\": 8,\n",
      "    \"highest judicial authority\": 9,\n",
      "    \"located in or next to body of water\": 10,\n",
      "    \"owner of\": 11,\n",
      "    \"place of death\": 12,\n",
      "    \"practiced by\": 13,\n",
      "    \"said to be the same as\": 14,\n",
      "    \"shares border with\": 15,\n",
      "    \"studied in\": 16\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 198\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 150\n",
      "  Number of trainable parameters = 65794577\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 03:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.752600</td>\n",
       "      <td>2.805400</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.006659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.693800</td>\n",
       "      <td>2.761990</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.034352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.462100</td>\n",
       "      <td>2.734746</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.039045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document. If document are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\merges.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ distilbert-base-cased Results: Accuracy = 0.1400, F1 = 0.0390, Loss = 2.7347\n",
      "\n",
      "🔄 Training & Evaluation: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"applies to jurisdiction\",\n",
      "    \"1\": \"award received\",\n",
      "    \"2\": \"characters\",\n",
      "    \"3\": \"conflict\",\n",
      "    \"4\": \"connects with\",\n",
      "    \"5\": \"different from\",\n",
      "    \"6\": \"diplomatic relation\",\n",
      "    \"7\": \"facet of\",\n",
      "    \"8\": \"founded by\",\n",
      "    \"9\": \"highest judicial authority\",\n",
      "    \"10\": \"located in or next to body of water\",\n",
      "    \"11\": \"owner of\",\n",
      "    \"12\": \"place of death\",\n",
      "    \"13\": \"practiced by\",\n",
      "    \"14\": \"said to be the same as\",\n",
      "    \"15\": \"shares border with\",\n",
      "    \"16\": \"studied in\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"applies to jurisdiction\": 0,\n",
      "    \"award received\": 1,\n",
      "    \"characters\": 2,\n",
      "    \"conflict\": 3,\n",
      "    \"connects with\": 4,\n",
      "    \"different from\": 5,\n",
      "    \"diplomatic relation\": 6,\n",
      "    \"facet of\": 7,\n",
      "    \"founded by\": 8,\n",
      "    \"highest judicial authority\": 9,\n",
      "    \"located in or next to body of water\": 10,\n",
      "    \"owner of\": 11,\n",
      "    \"place of death\": 12,\n",
      "    \"practiced by\": 13,\n",
      "    \"said to be the same as\": 14,\n",
      "    \"shares border with\": 15,\n",
      "    \"studied in\": 16\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--roberta-base\\snapshots\\e2da8e2f811d1448a5b465c236feacd80ffbac7b\\model.safetensors\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: document. If document are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 198\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 150\n",
      "  Number of trainable parameters = 124658705\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 08:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.723600</td>\n",
       "      <td>2.785784</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.012834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.732900</td>\n",
       "      <td>2.869185</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.012175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.693100</td>\n",
       "      <td>2.849882</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.006659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: document. If document are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: document. If document are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: document. If document are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: document. If document are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ roberta-base Results: Accuracy = 0.0600, F1 = 0.0067, Loss = 2.8499\n"
     ]
    }
   ],
   "source": [
    "model_names = ['distilbert-base-cased', 'roberta-base']\n",
    "results = []\n",
    "\n",
    "# Step 1: Correct label2id and id2label setup (should be defined earlier in your notebook)\n",
    "# Example:\n",
    "# all_labels = sorted({label for sublist in df[\"RE_label_set\"] for label in sublist})\n",
    "# label2id = {label: idx for idx, label in enumerate(all_labels)}\n",
    "# id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "# Step 2: Load tokenizer (can also be model-specific in loop)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "# Step 3: Tokenization function\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"document\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "# Step 4: Dataset preparation (assumes 'label' column is numeric)\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "split_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# Step 5: Metric computation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\")\n",
    "    }\n",
    "\n",
    "# Step 6: Fine-tuning and evaluation\n",
    "for model_name in model_names:\n",
    "    print(f\"\\n🔄 Training & Evaluation: {model_name}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label2id),\n",
    "        label2id=label2id,\n",
    "        id2label=id2label\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_{model_name.replace('/', '_')}\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"no\",\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=split_dataset[\"train\"],\n",
    "        eval_dataset=split_dataset[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_result = trainer.evaluate()\n",
    "    print(f\"✅ {model_name} Results: Accuracy = {eval_result['eval_accuracy']:.4f}, F1 = {eval_result['eval_f1']:.4f}, Loss = {eval_result['eval_loss']:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": eval_result[\"eval_accuracy\"],\n",
    "        \"f1\": eval_result[\"eval_f1\"],\n",
    "        \"loss\": eval_result[\"eval_loss\"]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eab0d3-a670-42bf-9188-8ccc52436ed6",
   "metadata": {},
   "source": [
    "## How many labels are acutally in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19031618-29d1-4289-83ac-1ad913018d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df[\"single_label\"].value_counts().plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecaaf83-f55b-468e-a6ca-6984c3e1dbb8",
   "metadata": {},
   "source": [
    "## easier single label training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb4277ff-1d22-4df6-9338-6ab9861c2a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmilo\\AppData\\Local\\Temp\\ipykernel_14320\\2414304673.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"label\"] = filtered_df[\"single_label\"].map(label2id)\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f842e059ec748c7b67f8e9a0e73a8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/122 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 97\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 65\n",
      "  Number of trainable parameters = 65785349\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 03:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.590800</td>\n",
       "      <td>1.596807</td>\n",
       "      <td>0.097902</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.539000</td>\n",
       "      <td>1.554100</td>\n",
       "      <td>0.236025</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.373400</td>\n",
       "      <td>1.459077</td>\n",
       "      <td>0.278519</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.217100</td>\n",
       "      <td>1.421125</td>\n",
       "      <td>0.239744</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.160900</td>\n",
       "      <td>1.400263</td>\n",
       "      <td>0.278519</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4002633094787598, 'eval_f1': 0.2785185185185185, 'eval_accuracy': 0.48, 'eval_runtime': 2.741, 'eval_samples_per_second': 9.121, 'eval_steps_per_second': 1.459, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# Nur häufige Klassen behalten (Top 5 Labels)\n",
    "top_labels = test_df[\"single_label\"].value_counts().index[:5]  \n",
    "filtered_df = test_df[test_df[\"single_label\"].isin(top_labels)].copy()\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(top_labels)}\n",
    "filtered_df[\"label\"] = filtered_df[\"single_label\"].map(label2id)\n",
    "\n",
    "# Huggingface Dataset vorbereiten\n",
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(filtered_df[[\"document\", \"label\"]])\n",
    "\n",
    "# Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"document\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Modelltraining\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./single_label_best\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        \"f1\": f1_score(p.label_ids, preds, average=\"macro\"),\n",
    "        \"accuracy\": accuracy_score(p.label_ids, preds)\n",
    "    }\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-cased\", num_labels=len(label2id)\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345be738-96cc-48f4-aed0-32a0369a7164",
   "metadata": {},
   "source": [
    "## Hyperparameter-Tuning-Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad8aa969-0b2d-4909-acde-7d17488feeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 97\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n",
      "  Number of trainable parameters = 65785349\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 01:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.550100</td>\n",
       "      <td>1.586690</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.382300</td>\n",
       "      <td>1.577990</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.348000</td>\n",
       "      <td>1.568351</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: LR=2e-05, Batch=4, Epochs=3 -> Accuracy=0.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 97\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 125\n",
      "  Number of trainable parameters = 65785349\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 03:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.557700</td>\n",
       "      <td>1.599666</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.367000</td>\n",
       "      <td>1.575585</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.234000</td>\n",
       "      <td>1.479189</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.134000</td>\n",
       "      <td>1.417486</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.092300</td>\n",
       "      <td>1.431450</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: LR=2e-05, Batch=4, Epochs=5 -> Accuracy=0.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 97\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 39\n",
      "  Number of trainable parameters = 65785349\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 01:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.567400</td>\n",
       "      <td>1.631291</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.566700</td>\n",
       "      <td>1.630528</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.488500</td>\n",
       "      <td>1.632853</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: LR=2e-05, Batch=8, Epochs=3 -> Accuracy=0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 97\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 65\n",
      "  Number of trainable parameters = 65785349\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 03:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.581600</td>\n",
       "      <td>1.595392</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.562600</td>\n",
       "      <td>1.619215</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.431100</td>\n",
       "      <td>1.624897</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.373800</td>\n",
       "      <td>1.563878</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.274400</td>\n",
       "      <td>1.560178</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: LR=2e-05, Batch=8, Epochs=5 -> Accuracy=0.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 97\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n",
      "  Number of trainable parameters = 65785349\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 02:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.532800</td>\n",
       "      <td>1.585831</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.294800</td>\n",
       "      <td>1.528891</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.201500</td>\n",
       "      <td>1.483259</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\nmilo/.cache\\huggingface\\hub\\models--distilbert-base-cased\\snapshots\\6ea81172465e8b0ad3fddeed32b986cdcdcffcf0\\model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: LR=3e-05, Batch=4, Epochs=3 -> Accuracy=0.4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\nmilo\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 97\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 125\n",
      "  Number of trainable parameters = 65785349\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='59' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 59/125 01:42 < 01:58, 0.56 it/s, Epoch 2.32/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.535600</td>\n",
       "      <td>1.582369</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.251900</td>\n",
       "      <td>1.493435</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: document, __index_level_0__. If document, __index_level_0__ are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 42\u001b[0m\n\u001b[0;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-cased\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(label2id)\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     32\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     33\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     }\n\u001b[0;32m     40\u001b[0m )\n\u001b[1;32m---> 42\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     43\u001b[0m metrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[0;32m     44\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1527\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1524\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1525\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1526\u001b[0m )\n\u001b[1;32m-> 1527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1528\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1529\u001b[0m     resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1530\u001b[0m     trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1531\u001b[0m     ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1532\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1775\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1773\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1778\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1780\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2523\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2522\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2523\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[0;32m   2525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2526\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2555\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2553\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2554\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2555\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   2556\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2557\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:761\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    759\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 761\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistilbert(\n\u001b[0;32m    762\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    763\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    764\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    765\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    766\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    767\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    768\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    769\u001b[0m )\n\u001b[0;32m    770\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[0;32m    771\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:579\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    578\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m    580\u001b[0m     x\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    581\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    582\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    583\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    584\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    585\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    586\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:354\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    352\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_state,)\n\u001b[1;32m--> 354\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    355\u001b[0m     x\u001b[38;5;241m=\u001b[39mhidden_state, attn_mask\u001b[38;5;241m=\u001b[39mattn_mask, head_mask\u001b[38;5;241m=\u001b[39mhead_mask[i], output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions\n\u001b[0;32m    356\u001b[0m )\n\u001b[0;32m    357\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:307\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    304\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa_layer_norm(sa_output \u001b[38;5;241m+\u001b[39m x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[1;32m--> 307\u001b[0m ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    308\u001b[0m ffn_output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer_norm(ffn_output \u001b[38;5;241m+\u001b[39m sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    310\u001b[0m output \u001b[38;5;241m=\u001b[39m (ffn_output,)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:248\u001b[0m, in \u001b[0;36mFFN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_chunking_to_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, \u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:246\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:253\u001b[0m, in \u001b[0;36mFFN.ff_chunk\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    251\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    252\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n\u001b[1;32m--> 253\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x)\n\u001b[0;32m    254\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "learning_rates = [2e-5, 3e-5, 5e-5]\n",
    "batch_sizes = [4, 8]\n",
    "epochs_list = [3, 5]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for lr, batch_size, epochs in itertools.product(learning_rates, batch_sizes, epochs_list):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./tuning_results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"no\",\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-cased\", num_labels=len(label2id)\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=split_dataset[\"train\"],\n",
    "        eval_dataset=split_dataset[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=lambda p: {\n",
    "            \"accuracy\": accuracy_score(p.label_ids, np.argmax(p.predictions, axis=1))\n",
    "        }\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    accuracy = metrics['eval_accuracy']\n",
    "    print(f\"Params: LR={lr}, Batch={batch_size}, Epochs={epochs} -> Accuracy={accuracy:.4f}\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params = {\"learning_rate\": lr, \"batch_size\": batch_size, \"epochs\": epochs}\n",
    "\n",
    "print(f\"Best Params: {best_params}, Best Accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb4cc63-983f-4c9c-bad3-2e22465d3906",
   "metadata": {},
   "source": [
    "## Visualizaztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86fe8a21-3fff-4e21-86a7-95833a942f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = [1, 2, 3, 4, 5]\n",
    "train_loss = [1.5628, 1.5286, 1.3041, 1.1241, 1.0599]\n",
    "val_loss = [1.6058, 1.5067, 1.4408, 1.3599, 1.3625]\n",
    "accuracy = [20, 48, 48, 52, 52]\n",
    "f1_score = [10.16, 26.13, 26.85, 34.02, 35.34]\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, 'o-', label=\"Train Loss\")\n",
    "plt.plot(epochs, val_loss, 'o-', label=\"Validation Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs. Validation Loss')\n",
    "plt.xticks(epochs)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, accuracy, 'o-', label=\"Accuracy (%)\")\n",
    "plt.plot(epochs, f1_score, 'o-', label=\"Macro F1-Score (%)\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score (%)')\n",
    "plt.title('Accuracy and Macro F1-Score')\n",
    "plt.xticks(epochs)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629116ef-b582-46f8-ab4a-36aaf288be7b",
   "metadata": {},
   "source": [
    "# 10. Documentation (READme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd97f31-0bb3-4016-83e5-5f8a22702ddb",
   "metadata": {},
   "source": [
    "# Relation Extraction Project Documentation\r\n",
    "\r\n",
    "## 🎯 Objective\r\n",
    "\r\n",
    "Fine-tune Transformer-based models (BERT, DistilBERT, RoBERTa) for document-level relation extraction, analyzing performance impacts from dataset characteristics and training strategies.\r\n",
    "\r\n",
    "## 🛠️ Methodology\r\n",
    "\r\n",
    "* **Dataset Preprocessing**:\r\n",
    "\r\n",
    "  * Converted multi-label data to a single-label format, focusing on the top-5 most frequent relations.\r\n",
    "  * Text tokenization with `DistilBERT-base-cased` tokenizer.\r\n",
    "  * Truncated and padded sequences to 512 tokens.\r\n",
    "\r\n",
    "* **Dataset Split**:\r\n",
    "\r\n",
    "  * Training: 80%\r\n",
    "  * Testing: 20%\r\n",
    "\r\n",
    "* **Model Training**:\r\n",
    "\r\n",
    "  * Transformer: `DistilBERT-base-cased`\r\n",
    "  * Epochs: 5\r\n",
    "  * Batch size: 8\r\n",
    "  * Learning rate: 3e-5\r\n",
    "  * Optimizer: AdamW\r\n",
    "\r\n",
    "* **Evaluation Metrics**:\r\n",
    "\r\n",
    "  * Accuracy\r\n",
    "  * Macro F1-Score\r\n",
    "\r\n",
    "## 📊 Results Overview\r\n",
    "\r\n",
    "| Epoch | Training Loss | Validation Loss | Accuracy (%) | Macro F1 (%) |\r\n",
    "| ----- | ------------- | --------------- | ------------ | ------------ |\r\n",
    "| 1     | 1.5628        | 1.6058          | 20.00        | 10.16        |\r\n",
    "| 2     | 1.5286        | 1.5067          | 48.00        | 26.13        |\r\n",
    "| 3     | 1.3041        | 1.4408          | 48.00        | 26.85        |\r\n",
    "| 4     | 1.1241        | 1.3599          | **52.00**    | 34.02        |\r\n",
    "| 5     | 1.0599        | 1.3625          | **52.00**    | **35.34**    |\r\n",
    "\r\n",
    "## 🚀 Model Comparison\r\n",
    "\r\n",
    "| Model Configuration                | Best Accuracy (%) | Best Macro F1 (%) |\r\n",
    "| ---------------------------------- | ----------------- | ----------------- |\r\n",
    "| DistilBERT (Best Performing Setup) | **52.00**         | **35.34**         |\r\n",
    "| DistilBERT (Hyperparameter Tuning) | 44.00             | 27.85             |\r\n",
    "| RoBERTa (Baseline, raw)            | 4.00              | 0.64              |\r\n",
    "| BERT (Baseline, multi-label)       | \\~0.00            | \\~8.84            |\r\n",
    "\r\n",
    "## 📌 Observations & Insights\r\n",
    "\r\n",
    "* Achieved clear **continuous improvement** across training epochs:\r\n",
    "\r\n",
    "  * Accuracy improved from 20% to 52%.\r\n",
    "  * Macro F1 improved significantly from \\~10% to \\~35%.\r\n",
    "\r\n",
    "* **Hyperparameter tuning** (varying epochs, learning rate, and batch size) was explored, but yielded **no performance improvement** beyond the initial optimized setup.\r\n",
    "\r\n",
    "* Low overall scores likely due to:\r\n",
    "\r\n",
    "  * **Dataset Limitations**:\r\n",
    "\r\n",
    "    * Small dataset size (\\~248 examples).\r\n",
    "    * Severe class imbalance, making rare relations difficult to learn.\r\n",
    "\r\n",
    "## 📉 Visualization\r\n",
    "\r\n",
    "* Clearly visualized accuracy, F1-score, training, and validation loss over epochs.\r\n",
    "* Highlighted stable improvements, reinforcing robustness despite limited data.\r\n",
    "\r\n",
    "## ✅ Conclusion\r\n",
    "\r\n",
    "* **Optimal model setup**: DistilBERT, batch size 8, learning rate 3e-5, trained for 5 epochs.\r\n",
    "* Primary performance limitation: Dataset size and imbalance.\r\n",
    "* Methodological rigor was maintained throughout.\r\n",
    "\r\n",
    "## ⚠️ Recommendations for Future Work\r\n",
    "\r\n",
    "* Increase dataset size and diversity to better train generalized models.\r\n",
    "* Implement cross-validation to strengthen evaluation robustness.\r\n",
    "* Investigate advanced data augmentation or transfer learning strategies.\r\n",
    "\r\n",
    "## 📚 Final Note\r\n",
    "\r\n",
    "* Current results reflect careful and methodologically sound work, demonstrating clear iterative imprvement and providing strong analytical insights into challenges posed by the dataset.\r\n",
    "oversampling, augmentation).\r\n",
    "4. Document insights and improvements for iterative refinement and future work.\r\n",
    "* für produktiven Einsatz.\r\n",
    "over the baseline.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b371ebe-d02c-40b3-ac42-9c41832b7b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
